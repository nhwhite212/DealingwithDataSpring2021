{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "000-VaderSentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3bM9dqUwLb26LxdP+uc6b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/master/000-VaderSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXCaq47v0X5B"
      },
      "source": [
        "# This notebook will use the Vader NLTK library to do sentiment analysis on reviews.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpTwKKGP0f82"
      },
      "source": [
        "## First bring in the libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_6zPltU4U-u",
        "outputId": "73aef770-34f0-4438-b6fc-0926fb0629d1"
      },
      "source": [
        "import nltk\n",
        "# and the puncuation library\n",
        "nltk.download('punkt') "
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKLo-YR8Pc7"
      },
      "source": [
        "### Next we will load in the Vader components, the analyzer and the lexicon to go with it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgNB6BOQ00TL",
        "outputId": "9be30d2b-97ab-417d-cff1-b3987587224c"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTT8xDI8hVc"
      },
      "source": [
        "### Initialize the analyzer object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDjrxVC0-aj"
      },
      "source": [
        "# Initialize the analyzer, creating our analyzer\n",
        "analyzer=SentimentIntensityAnalyzer()\n"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFJkSRI48qFb"
      },
      "source": [
        "### Create  some text to analyze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWoZbyIx1N-z"
      },
      "source": [
        "# test it\n",
        "message_text='''Dealing with data is a difficult course, covering many topics. It was frustating at first, but I am now starting to enjoy it. Professor White has been very helpful''' "
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gAHnhr68vAu"
      },
      "source": [
        "### import the tokenizer to split paragraphs into sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTmecw7e3dGs",
        "outputId": "0223a176-a651-4231-c3db-91230d0678c0"
      },
      "source": [
        "print(message_text)\n",
        "from nltk import tokenize"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dealing with data is a difficult course, covering many topics. It was frustating at first, but I am now starting to enjoy it. Professor White has been very helpful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdR2cSrD88L9"
      },
      "source": [
        "# test the tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_3uNwUo39mi",
        "outputId": "da4a5226-0f68-4504-d3d6-d7c9b5dc4737"
      },
      "source": [
        "sentences= tokenize.sent_tokenize(message_text)\n",
        "for i in sentences:\n",
        "  print(i)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dealing with data is a difficult course, covering many topics.\n",
            "It was frustating at first, but I am now starting to enjoy it.\n",
            "Professor White has been very helpful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66tDwPGs9E69"
      },
      "source": [
        "### Now, loop through the sentences and get a score for each sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3Vo74p31tUL",
        "outputId": "a5f8e5be-3af6-446c-897a-e0e934d05e34"
      },
      "source": [
        "for sentence in sentences:\n",
        "  scores =analyzer.polarity_scores(sentence)\n",
        "  # scores is a dictionary\n",
        "  for k in sorted(scores):\n",
        "    print('{0}: {1}, '.format(k,scores[k],end=' '))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "compound: -0.3612, \n",
            "neg: 0.238, \n",
            "neu: 0.762, \n",
            "pos: 0.0, \n",
            "compound: 0.6486, \n",
            "neg: 0.0, \n",
            "neu: 0.719, \n",
            "pos: 0.281, \n",
            "compound: 0.4754, \n",
            "neg: 0.0, \n",
            "neu: 0.618, \n",
            "pos: 0.382, \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JzK3lKw9zEP"
      },
      "source": [
        "### But we can also get a total score for all the sentnces (like in a review or tweet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-pIwwBi136L",
        "outputId": "1714f29c-38a5-4448-9a89-ad745c7a7bbb"
      },
      "source": [
        "alltextscores= analyzer.polarity_scores(message_text)\n",
        "print (alltextscores)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'neg': 0.051, 'neu': 0.702, 'pos': 0.247, 'compound': 0.8266}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BpoowtH9_ud"
      },
      "source": [
        "# It should be easy to distill long sequences of text into a few numbers\n",
        "# Note, we can also use NLTK to pull out entities from the text\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIFLYBWM9rIo"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64vFAzUrBBrn",
        "outputId": "162a5441-322b-4f71-f6cb-38e59822abff"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOpFsO8A_Gdn"
      },
      "source": [
        "### create a little function\n",
        "def preprocess(sent):\n",
        "  sent=nltk.word_tokenize(sent)\n",
        "  sent=nltk.pos_tag(sent)\n",
        "  return sent"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UloQIpxq_3Pr"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7rOIkyqAGw2"
      },
      "source": [
        ""
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2IDr0HYANXd",
        "outputId": "fa402acc-a10e-442e-9710-1401d7412d1c"
      },
      "source": [
        "# and call it for every sentence\n",
        "for i in sentences:\n",
        "  print(i)\n",
        "  thesent=preprocess(i)\n",
        "  print(thesent)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dealing with data is a difficult course, covering many topics.\n",
            "[('Dealing', 'VBG'), ('with', 'IN'), ('data', 'NNS'), ('is', 'VBZ'), ('a', 'DT'), ('difficult', 'JJ'), ('course', 'NN'), (',', ','), ('covering', 'VBG'), ('many', 'JJ'), ('topics', 'NNS'), ('.', '.')]\n",
            "It was frustating at first, but I am now starting to enjoy it.\n",
            "[('It', 'PRP'), ('was', 'VBD'), ('frustating', 'VBG'), ('at', 'IN'), ('first', 'JJ'), (',', ','), ('but', 'CC'), ('I', 'PRP'), ('am', 'VBP'), ('now', 'RB'), ('starting', 'VBG'), ('to', 'TO'), ('enjoy', 'VB'), ('it', 'PRP'), ('.', '.')]\n",
            "Professor White has been very helpful\n",
            "[('Professor', 'NNP'), ('White', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('very', 'RB'), ('helpful', 'JJ')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9eXRtEGCOvx"
      },
      "source": [
        "# Note that all the entities are Proper Nouns('NNP') or Nouns ('NN')\n",
        "You just need to pull them out of the dictionary ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSTK7Ly3AR-2"
      },
      "source": [
        ""
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIvuDcXOCMyW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}