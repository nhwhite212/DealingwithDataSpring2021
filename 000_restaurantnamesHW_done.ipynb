{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.5"
    },
    "colab": {
      "name": "000-restaurantnamesHW-done.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/master/000_restaurantnamesHW_done.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN406dNQKKWm"
      },
      "source": [
        "# Our Task: Find similar company names\n",
        "\n",
        "Now that we have completed our Python Primer, let's try to complete a real task, while at the same time trying to practice loops, iterations, and other Python functionality that we studied.\n",
        "\n",
        "### Your high level task\n",
        "\n",
        "You are given a list of names. You know that the same entity in the list has different representations. You want to find duplicate companies in the data.\n",
        "\n",
        "As a concrete example, open the file under `data/restaurants.txt`. This contains a list of restaurant names, extracted from the [NYC Restaurant inspection data set](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/xx67-kt59/data) (available online). The Department of Health has been doing a decent, but not perfect, job in recording the company names. Therefore, the same restaurant appears under different names. **Your task is to find \"almost duplicate\" entries in order to decide whether they correspond to the same business.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNVMJQ-zKKWn"
      },
      "source": [
        "#### Matching Company Names\n",
        "\n",
        "Quite often, in our data, we have entries represented as strings that refer to the same entity but have different string representations (e.g., McDonald's vs McDonalds vs McDonald‎). We want to write code that will help in the task of finding such similar entries in our data.\n",
        "\n",
        "Our task can be broken in the following tasks:\n",
        "* **Step 1**: Read the data from a file into a list of strings in memory. We have a data set under the `/data` folder: The list of unique restaurant names from the NYC Restaurant Inspection dataset (`uniquenames.txt`). We need to write Python code that will read th file and return a list of strings that are the company names.\n",
        "* **Step 2**: We will then need to figure out how to compare two strings and find their similarity. For that, we will write a function that takes as input **two** strings, and returns back their similarities. We will explore multiple ways of writing that function, using various library functions.\n",
        "* **Step 3**: We will need to write a function that takes as input a company name, and returns back a list of matching company names, together with their similarity. Ideally, we would like to also sort the list based on the similarity (highest similarity metrics on top). As part of our learning process, we will use the _list comprehension_ approach to create the list. We will also use tuples as the elements of the list, so that the list contain elements such as `[(\"McDonalds\", 0.88), (\"McDonald's\", 0.81),....]`.\n",
        "* **Step 4**: In the final step, we will just perform the similarity computation across all companies in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LCLCVThKKWo"
      },
      "source": [
        "### STEP 1: Read the list of names from a file and create a list of names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex7Gtx6SKKWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6628bdd0-5e2f-4e28-88da-98d83d65fcb9"
      },
      "source": [
        "# STEP 1: Read the list of names from a file and create a list of names\n",
        "# First download the file using curl\n",
        "!curl 'http://people.stern.nyu.edu/nwhite/DealingwithDataSpring2021/data/uniquenames.txt' >uniquenames.txt\n",
        "!head -100 uniquenames.txt\n",
        "filename = 'uniquenames.txt'\n",
        "f= open(filename,'r')\n",
        "companyList=f.read().split('\\n')\n",
        "print(len(companyList))\n",
        "print(companyList[100:200])\n",
        "\n",
        "#your code here"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  364k  100  364k    0     0   632k      0 --:--:-- --:--:-- --:--:--  631k\n",
            "#1 GARDEN CHINESE\n",
            "#1 ME. NICK'S\n",
            "#1 SABOR LATINO RESTAURANT\n",
            "$1.25 PIZZA\n",
            "''U'' LIKE CHINESE RESTAURANT\n",
            "''W'' CAFE\n",
            "'WICHCRAFT\n",
            "(LEWIS DRUG STORE) LOCANDA VINI E OLII\n",
            "(LIBRARY)  FOUR & TWENTY BLACKBIRDS\n",
            "(PUBLIC FARE) 81ST STREET AND CENTRAL PARK WEST (DELACORTE THEATRE)\n",
            "/ L'ECOLE\n",
            "002 MERCURY TACOS LLC\n",
            "1 2 3 BURGER SHOT BEER\n",
            "1 BANANA QUEEN\n",
            "1 BUEN SABOR\n",
            "1 DARBAR\n",
            "1 EAST 66TH STREET KITCHEN\n",
            "1 OAK\n",
            "1 OR 8\n",
            "1 STOP PATTY SHOP\n",
            "1.5 GALBI CORP\n",
            "10 DEVOE\n",
            "10 POINTS KTV\n",
            "100 FUN\n",
            "100% PATACON CACHAPA YAROA\n",
            "100% SMOOTHIES & EMPANADAS\n",
            "1001 NIGHTS\n",
            "1001 NIGHTS CAFE\n",
            "1005 CATERING\n",
            "101 CAFE\n",
            "101 DELI\n",
            "101 RESTAURANT AND BAR\n",
            "102 NOODLES TOWN RESTAURANT\n",
            "1020 BAR\n",
            "1028 BAR & RESTAURANT EL SALVADORENO \n",
            "104-01 FOSTER AVENUE COFFEE SHOP(UPS)\n",
            "1061 CATERING LLC\n",
            "107 WEST RESTAURANT\n",
            "108 FAST FOOD CORP\n",
            "108 LOUNGE - CLUB 108\n",
            "1081 FULTON\n",
            "10TH AVENUE COOKSHOP\n",
            "10TH AVENUE PIZZA & CAFE\n",
            "11 STREET CAFE\n",
            "111 RESTAURANT\n",
            "1174 FULTON CUISINE, HALAL FOOD\n",
            "12 CHAIRS\n",
            "12 CHAIRS CAFE\n",
            "12 CORAZONES RESTAURANT & BAR\n",
            "12 CORNERS\n",
            "12 CORNERS COFFEE INC\n",
            "12 STREET ALE HOUSE\n",
            "120 BAY CAFE\n",
            "1200 MILES\n",
            "121 FULTON STREET\n",
            "123 NIKKO\n",
            "124 COFFEE SHOP\n",
            "128 DUMPLING HOUSE\n",
            "12TH STREET BAR & GRILL\n",
            "137 BAR & GRILL\n",
            "1380 BRONX RIVER CAFE CORP\n",
            "149 STEAM FISH CORP.\n",
            "14TH STREET PIZZA BAGEL CAFE\n",
            "15 CENTRAL PARK WEST RESTAURANT\n",
            "15 EAST RESTAURANT\n",
            "15 FLAVORS\n",
            "15 FLAVORS \n",
            "15 ST CAFE\n",
            "156 TEX BAR AND LOUNGE\n",
            "16 HANDLES\n",
            "16 HANDLES FROZEN YOGURT\n",
            "16 HANDLES MIDWOOD\n",
            "1617-A NATIONAL BAKERY\n",
            "162 EB CORP BAKERY\n",
            "168 ASUKA SUSHI\n",
            "168 BOWERY HOLDING LLC\n",
            "168 HI TEA\n",
            "168 TEA LLC\n",
            "169 BAR\n",
            "16TH AVENUE GLATT\n",
            "1734 VICTORY BOULEVARD,INC.\n",
            "18 BAKERY\n",
            "18 CHINESE CUISINE\n",
            "18 EAST GUNHILL PIZZA\n",
            "18 HIPOT\n",
            "18 RESTAURANT\n",
            "18 STARS KITCHEN\n",
            "181 ST CARIDAD RESTAURANT\n",
            "1818 SEAFOOD RESTAURANT\n",
            "187 YANG GARDEN\n",
            "188 FAST FOOD INC\n",
            "19 CAFE\n",
            "1962 SOGONGDONG SONTOFU\n",
            "19A EMPIRE RESTAURANT\n",
            "1A STORE INC\n",
            "1ST AVENUE GOURMET\n",
            "1ST BASE CONCESSION STAND\n",
            "1ST MAMA RESTAURANT\n",
            "1ST STOP\n",
            "2 BROS\n",
            "20444\n",
            "['2 BROS PIZZA', '2 BROTHERS RESTAURANT', '2 CHILL', '2 DUCK GOOSE', '2 IN 1 RESTAURANT', '2 PALMITAS MEXICAN DELI', '200 FIFTH AVENUE RESTAURANT & SPORTS BAR', '200 ORCHARD BAR', '201 BAR AND RESTAURANT', '2013 BROOKLYN RESTAURANT', '203 LENA INC', '2058 DELI AND GROCERY', '21 BAR', '21 CLUB', '21 SHANGHAI HOUSE', '21+ LOUNGE.', '211 NEW TACO GRILL', '212 SHAWARMA GRILL', '212 STEAKHOUSE', '216 GOOD JOY CHINESE RESTAURANT', '218 RESTAURANT', '22 THAI CUISINE', '224TH CORNER RESTAURANT & BAKERY', '229 LINDEN RESTAURANT', '230 FIFTH', '232 WILLIS AVENUE FOODS, LLC', '234 CHINA CITY', '2419 CHINA STAR RESTAURANT', '241ST CAFE RESTAURANT', '2432 PEKING HOUSE INC', '2460 LUCKY GARDEN', '248 HOSPITALITY GROUP LLC', '25TH DELI', '26 SEATS', '2647 DOUBLE DRAGON CHINESE RESTAURANT', '27 SHENG WANG NOODLE SHOP', '27 SHINJUKU SUSHI INC', '27 SPORTS BAR & CAFE', \"28 MR. MING'S CAFFE\", '28 NOODLES', '286 PIZZA PLACE INC', '29TH STREET HOTEL ACQUISITION LLC', '2A', '2FL', '2ND AVE BLUE 9 BURGER', '2ND AVENUE DELI', '3 ALARM', \"3 D'S LEGACY SALAD & GRILL\", '3 DELI & GRILL', '3 ESQUINAS RESTAURANT', '3 GUYS', '3 GUYS RESTURANT', '3 IN 1 FS&H JAMAICAN RESTAURANT', '3 IN 1 KITCHEN', '3 MOUNTS', '3 ROOTS', '3 SHEETS SALOON', \"3 SISTERS' & SHANTA'S RESTAURANT & BAKERY\", '3 STAR JUICE CENTER', '3 WAY RESTAURANT', '3-J RESTAURANT AND PIZZA', '301 CAFE JUICE AND SMOOTHIES', '310 - EXELSIOR', '318 - TWO BOOTS', '31ST AVENUE GYRO.', '32 DEGREE FROYO LOUNGE', '33 GOURMET', '337 - BURGERS & DOGS', '3463 JUICES FOR LIFE LLC', '35 DUET', '36-02 DITMARS COFFEE CORP.', '360 LOUNGE', '36TH AVE COFFEE SHOP', '374 DELI', '38 DELI', '388 CAFE & DELI', '38TH STREET DINER', '39 COFFEE SHOP', '39 KARAOKE', '395 GOURMET AND GROCERY', '3E TASTE OF THAI', '3RD & 7', '40/40 CLUB', '40/40 CLUB BAR', '401 LUCKY STAR RESTAURANT', '40TH ROAD LUNCH BOX', '414 HOTEL', '414 LATINO RESTAURANT SPORTS BAR', '42ND STREET PIZZA DINER', \"44 & X HELL'S KITCHEN\", '44 1/2 CAFE', '44 SW RISTORANTE & BAR', '444 MADISON COFFEE SHOP', '44TH STREET MINAR', '44TH STREET PIZZA', '456 RESTAURANT', '4618 BAKERY', '46TH ST STATION HOUSE', '49 GROVE', '4D']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlAXE0NOKKWq"
      },
      "source": [
        "### STEP 2: Implement the similarity function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-z30ECunKKWr"
      },
      "source": [
        "### Computing the similarity between two strings\n",
        "\n",
        "There are many ways that we can calculate the similarity between two strings. For our case, we will focus on a few similarity metrics that already have implementations in Python. \n",
        "\n",
        "##### Some commonly used similarity metrics\n",
        "\n",
        "* [Sequence matching](https://docs.python.org/3.6/library/difflib.html) (part of standard Python) ([example](http://stackoverflow.com/questions/17388213/find-the-similarity-percent-between-two-strings))\n",
        "* [Edit distance](https://en.wikipedia.org/wiki/Edit_distance) ([Python Jellyfish Library](https://github.com/jamesturk/jellyfish))\n",
        "* [N-gram distance](http://pythonhosted.org/ngram/tutorial.html#comparing-and-searching-strings)\n",
        "\n",
        "\n",
        "#### STEP 2.a: Let's figure out how we can install the libraries..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMP54uNaKKWr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcbd5cc1-e649-404e-aa28-c925856f891c"
      },
      "source": [
        "# Edit distance\n",
        "!sudo pip3 install -U jellyfish"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jellyfish\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/a6/4d039bc827a102f62ce7a7910713e38fdfd7c7a40aa39c72fb14938a1473/jellyfish-0.8.2-cp37-cp37m-manylinux2014_x86_64.whl (90kB)\n",
            "\r\u001b[K     |███▋                            | 10kB 11.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 20kB 16.6MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 30kB 11.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 61kB 6.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 71kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 81kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.9MB/s \n",
            "\u001b[?25hInstalling collected packages: jellyfish\n",
            "Successfully installed jellyfish-0.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMbSWEQwKKWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f890f67-1ace-435f-ec6a-3824ab3bac3e"
      },
      "source": [
        "# Ngram\n",
        "!sudo pip3 install -U ngram"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ngram\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/84/707fdecbe63e67345db200a86274686d58fd3da805da53c80c5942d90393/ngram-3.3.2.tar.gz\n",
            "Building wheels for collected packages: ngram\n",
            "  Building wheel for ngram (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ngram: filename=ngram-3.3.2-cp37-none-any.whl size=24713 sha256=1e10e422f367a8998aa3f48886be59568028f8db53f14f2d72524534dd59bbaf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/d5/5a/6abe3035c83a606376089accde30b021ffb26593f0d6609ef1\n",
            "Successfully built ngram\n",
            "Installing collected packages: ngram\n",
            "Successfully installed ngram-3.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCDnMfwEKKWs"
      },
      "source": [
        "#### STEP 2.b: Now let's test our similarity functions with various examples\n",
        "\n",
        "Once we have installed the necessary libraries for our project, we proceed to `import` them and test the functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S981EOFUKKWs"
      },
      "source": [
        "import jellyfish"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A3yuO2RKKWt"
      },
      "source": [
        "##### Edit Distance\n",
        "\n",
        "From Wikipedia:\n",
        "\n",
        "The [edit distance](https://en.wikipedia.org/wiki/Edit_distance) _ is a way of quantifying how dissimilar two strings (e.g., words) are to one another by counting the minimum number of operations required to transform one string into the other._. \n",
        "\n",
        "The Levenshtein distance between \"kitten\" and \"sitting\" is 3. A minimal edit script that transforms the former into the latter is:\n",
        "\n",
        "* kitten → sitten (substitution of \"s\" for \"k\")\n",
        "* sitten → sittin (substitution of \"i\" for \"e\")\n",
        "* sittin → sitting (insertion of \"g\" at the end)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WYZ-NBFKKWu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b9fc51-133f-4242-f520-e570b0c0129e"
      },
      "source": [
        "jellyfish.levenshtein_distance('kitten', 'sitting')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWofMHALKKWu"
      },
      "source": [
        "Let's try a few more examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7c-M0_2KKWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ab789f8-f7a0-4bab-a64a-b1865edd05ca"
      },
      "source": [
        "jellyfish.levenshtein_distance('Starbucks', 'Starbacks')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR3b_xn5KKWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acb37a6a-6ded-4f97-9a1c-7a9d48b15761"
      },
      "source": [
        "jellyfish.levenshtein_distance('Starbucks', 'Starbuck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnVwwOIeKKWv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea31b3f6-26aa-474e-af57-c81bc83e1b8f"
      },
      "source": [
        "jellyfish.levenshtein_distance('Starbucks', 'Wendys')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nf4AVsM_KKWv"
      },
      "source": [
        "##### Demerau Levenshtein distance\n",
        "\n",
        "The Demerau Levenshtein distance also allows for  transposition of two adjacent characters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-xQ38oUKKWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1670da1c-f880-47f7-8c39-b3fd15e85d31"
      },
      "source": [
        "jellyfish.damerau_levenshtein_distance('Starbucks', 'Starbucsk')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Lnpk3SKKWw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d30adb87-d45f-4fe7-8519-5ab6e4b5d1cb"
      },
      "source": [
        "jellyfish.levenshtein_distance('Starbucks', 'Starbucsk')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To8ndsmeKKWw"
      },
      "source": [
        "###### Jaro–Winkler distance\n",
        "\n",
        "[Jaro–Winkler distance](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) is a string metric for measuring the edit distance between two sequences. Informally, the **Jaro** distance between two words is the minimum number of single-character transpositions required to change one word into the other; the **Jaro–Winkler** distance  gives more favourable ratings to strings that match from the beginning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC5URLaGKKWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e120715-2ff3-47d3-f91a-ea7c64f1432a"
      },
      "source": [
        "jellyfish.jaro_winkler('Starbucks', 'Starbarbr')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8222222222222222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjk0uMXfKKWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "898f8e1b-b95c-4e38-b0f1-7512d166d1a6"
      },
      "source": [
        "jellyfish.jaro_winkler('Starbucks', 'Milwbucks')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7037037037037037"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHEKEs9-KKWx"
      },
      "source": [
        "##### Soundex\n",
        "\n",
        "[Soundex](https://en.wikipedia.org/wiki/Soundex) is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. \n",
        "\n",
        "Using this algorithm, both \"Robert\" and \"Rupert\" return the same string \"R163\" while \"Rubin\" yields \"R150\". \"Ashcraft\" and \"Ashcroft\" both yield \"A261\". \"Tymczak\" yields \"T522\" not \"T520\" (the chars 'z' and 'k' in the name are coded as 2 twice since a vowel lies in between them). \"Pfister\" yields \"P236\" not \"P123\" (the first two letters have the same number and are coded once as 'P')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej9Uia0oKKWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "967f7117-0d93-4bf2-a398-6a9203f802a1"
      },
      "source": [
        "jellyfish.soundex('Robert')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'R163'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl6miHD4KKWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fd00269d-a4ee-4651-f59f-a0c9e9381126"
      },
      "source": [
        "jellyfish.soundex('Rupert')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'R163'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj-k1dWrKKWy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a5d0c2f3-f975-4ed8-a4a4-2dd4aec42ac1"
      },
      "source": [
        "jellyfish.soundex('Ashcroft')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A261'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1fJZDl1KKWz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aa388643-7622-492e-c829-73e86d703b28"
      },
      "source": [
        "jellyfish.soundex('Ashcraft')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A261'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hx5hzANKKWz"
      },
      "source": [
        "#### Ngrams\n",
        "\n",
        "With the n-gram similarity score, we split the word into sequences of n consecutive characters (n-grams) and then compare the sets of n-grams between the two words. For example, the name \"Panos\" has the following 2-grams: \"Pa\", \"an\", \"no\", \"os\". (We can also add \"#P\" and \"s#\" if we want to capture the prefix and suffixes.) Strings that share a large number of q-grams are often similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJLGFRueKKWz"
      },
      "source": [
        "import ngram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydU0QY2EKKWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515f5047-c569-46d2-f544-04568b95b3a5"
      },
      "source": [
        "ngram.NGram.compare('Ipeirotis','Iperotis',N=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7272727272727273"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arr3GZHcK-wz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "774f97b0-4b33-4ba5-815c-7fffda2c12f4"
      },
      "source": [
        "ngram.NGram.compare('White','Whyte',N=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmHttqr2KKWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a27d82d2-8964-4e4f-df10-f54f198de4a5"
      },
      "source": [
        "ngram.NGram.compare('New York University','New York Universty',N=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8571428571428571"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaceK9UOKKWz"
      },
      "source": [
        "#### Task 1: Create a function that takes as input two strings and returns their similarity\n",
        "\n",
        "Given the experience with the metrics above, we want now to create a *function* that takes as input a string and returns their similarity. Our key requirement is for the similarity metric to be between 0 and 1, with 0 meaning no similarity, and 1 corresponding to identical strings. Some of the similarity functions above would fit right in, others will need some work. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DSDEDf-KKWz"
      },
      "source": [
        "# For n-gram similarity it is very simple, we just return the result\n",
        "def computeSimilarity(str1, str2):\n",
        "    #your code here\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcuQYpa-KKWz"
      },
      "source": [
        "#### Task 2: Modify the functions above to allow for various similarity calculation methods.\n",
        "\n",
        "We will now up our game, and return back the results of the comparison using various methods. The `method` parameter defines the metric that we will use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgj_onRSKKW0"
      },
      "source": [
        "def computeSimilarity(str1, str2, method):\n",
        "    #your code here\n",
        "    return\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyngMD0jNmZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96803d76-4f9c-427f-e250-3ff7da4b304e"
      },
      "source": [
        "### nhw cell\n",
        "def computeSimilarity(str1,str2,method):\n",
        "  # str1 and str2 are strings with company names\n",
        "  # method is either '2-gram','jacquard', 'levenshtein', 'jaro_winkler', or 'soundex'\n",
        "  if(method=='2-gram'):\n",
        "    return ngram.NGram.compare(str1,str2,N=2)\n",
        "  if(method=='jacquard'):\n",
        "    intsize=len(set(str1).intersection(set(str2)))\n",
        "    unionsize= len(set(str1).union(set(str2)))\n",
        "    return intsize/unionsize\n",
        "  if(method=='jaro_winkler'):\n",
        "    return jellyfish.jaro_winkler(str1,str2)\n",
        "  if (method=='levenshtein'):\n",
        "    return 1.0- (jellyfish.levenshtein_distance(str1,str2)/max(len(str1),len(str2)))\n",
        "  if(method=='soundex'):\n",
        "    if (jellyfish.soundex(str1)== jellyfish.soundex(str2)):\n",
        "      return 1.0\n",
        "  return 0.0\n",
        "                                      \n",
        "s1='mcdonalds'\n",
        "s2='macdonaldsaaa'\n",
        "for m in ['2-gram','jacquard','levenshtein','jaro_winkler','soundex'] :\n",
        "  sim=computeSimilarity(s1,s2,m)\n",
        "  print(sim)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n",
            "1.0\n",
            "0.6923076923076923\n",
            "0.841025641025641\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utscrMjwKKW0"
      },
      "source": [
        "### STEP 3: Compute similarity of a company against a list of company names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ot-SKjJKKW0"
      },
      "source": [
        "We now create a function that accepts a company name and a list of companies, and computes their similarity. This part will get us to exercise our for-loops, and also illustrate how we can use lists and tuples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HhQ64lWKKW0"
      },
      "source": [
        "**Sorting a list of tuples**:_This part is a little bit advanced for now, so I will just give the code below. (Solution taken from http://stackoverflow.com/questions/3121979/how-to-sort-list-tuple-of-lists-tuples). Here is a small example below, which we will reuse in our function:_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZUZN7Z7KKW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78fe037f-2368-4b20-87ca-9ff1463054cd"
      },
      "source": [
        "data = [(\"Panos\",0.5), (\"Peter\",0.6), (\"Pan\", 0.4)]\n",
        "data.sort(key=lambda tupl: tupl[1], reverse=True)  # sorts in place, in descending order, based on the second element of the tuple\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('Peter', 0.6), ('Panos', 0.5), ('Pan', 0.4)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftygeyNAKKW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dacb28ea-80c6-46ce-e13b-a5e8629e58db"
      },
      "source": [
        "# STEP 3: We now create a function that accepts a company name\n",
        "# and a list of companies, and computes their similarity\n",
        "# We have a 'top' parameter (by default set to be 5)\n",
        "# that restricts the results to only the most similar \n",
        "# string pairs. We also define a parameter \"method\" that defines \n",
        "# what is the similarity method that we want to use. We also define a \n",
        "# similarity threshold for keeping only results with sufficient similarity\n",
        "\n",
        "def companySimilarity(query, companyList, top = 5, method = '2-gram', sim_threshold = 0.5):\n",
        "    #your code here\n",
        "  thelist=[]\n",
        "  for company in companyList:\n",
        "    thesim=computeSimilarity(query.upper(),company.upper(),method)\n",
        "    if(thesim> sim_threshold):\n",
        "      thelist.append((company,round(thesim,2)))\n",
        "  # now sort the list\n",
        "  thelist.sort(key=lambda tupl: tupl[1], reverse=True)\n",
        "\n",
        "  return thelist[0:5]\n",
        "\n",
        "# Test the function \n",
        "sim=companySimilarity('McDonalds', companyList, top = 5, method ='2-gram', sim_threshold=.5)\n",
        "print(sim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('MCDONALDS', 1.0), ('MC DONALDS', 0.75), (\"MCDONALD'S\", 0.75), ('MCDONALD', 0.73), (\"MC DONALD'S\", 0.57)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpuZJrgQKKW1"
      },
      "source": [
        "### Step 4: Perform the similarity computation across a random set of companies in the dataset.lets pick 10 at random to test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAiYUvLFKKW1"
      },
      "source": [
        "# STEP 4: We are almost done. We now just go through a random set of the companies in the list\n",
        "# and we call the companySimilarity function that computes the similar company names\n",
        "# for all the companies in the list. We store the results in a dictionary, with the \n",
        "# key being the company name, and the value being a \"list of tuples\" with the \n",
        "# similar company names and the corresponding similarity value.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d5WeVZpKKW1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30f39166-215a-44a9-d127-c239f601263f"
      },
      "source": [
        "#your code here\n",
        "import random\n",
        "thelist=[]\n",
        "# generate a numbe rbetween 1 and the number of companies\n",
        "ncomps=len(companyList)\n",
        "adraw=random.sample(companyList,k=50)\n",
        "#print(adraw)\n",
        "thesims={}\n",
        "for comp in adraw:\n",
        "  thesims[comp]=companySimilarity(comp,companyList,top=5,method='2-gram',sim_threshold=.5)\n",
        "  \n",
        "for i in thesims:\n",
        "  if (len(thesims[i]))>1:\n",
        "      print(i, \" ====> \",thesims[i])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "THE AVENUE  ====>  [('THE AVENUE', 1.0), ('D AVENUE', 0.54)]\n",
            "GARIBALDI DELI RESTAURANT  ====>  [('GARIBALDI DELI RESTAURANT', 1.0), ('GALLI RESTAURANT', 0.59), ('ONE DELI RESTAURANT', 0.53), ('SPARKS DELI RESTAURANT', 0.53)]\n",
            "CASTILLO DE JAGUA DELI RESTAURANT  ====>  [('CASTILLO DE JAGUA DELI RESTAURANT', 1.0), ('GRAN CASTILLO DE JAGUA RESTAURANT', 0.7), ('EL CASTILLO DE JAGUA REST', 0.62), ('EL CASTILLO DE JAQUE RESTAURANT', 0.61), ('CASTILLO RESTAURANT', 0.59)]\n",
            "SING GARDEN RESTAURANT  ====>  [('SING GARDEN RESTAURANT', 1.0), ('SPRING GARDEN RESTAURANT', 0.85), ('KING GARDEN RESTAURANT', 0.84), ('SPRING GARDENS RESTAURANT', 0.75), ('SING WEN RESTAURANT', 0.72)]\n",
            "HOWONG RESTAURANT  ====>  [('HOWONG RESTAURANT', 1.0), ('HOP WONG RESTAURANT', 0.81), ('HOY WONG RESTAURANT', 0.81), ('WONG RESTAURANT', 0.79), ('HAN WONG RESTAURANT', 0.73)]\n",
            "TAKA HASHI RESTAURANT  ====>  [('TAKA HASHI RESTAURANT', 1.0), ('HASAKI RESTAURANT', 0.6), ('YA SHI RESTAURANT', 0.6), ('CHAI HWA RESTAURANT', 0.56), ('PLAKA RESTAURANT', 0.56)]\n",
            "BA1019 BAR  ====>  [('BA1019 BAR', 1.0), ('BA1002 BAR', 0.57)]\n",
            "PABLO'S PIZZA  ====>  [(\"PABLO'S PIZZA\", 1.0), (\"PINO'S PIZZA\", 0.59), (\"PAESANO'S PIZZA\", 0.58), (\"PICCOLO'S PIZZA\", 0.58), (\"LELLO'S PIZZA\", 0.56)]\n",
            "GALLITO'S KITCHEN  ====>  [(\"GALLITO'S KITCHEN\", 1.0), (\"LI'S KITCHEN\", 0.55), (\"LOLITA'S KITCHEN\", 0.52)]\n",
            "CITY DINER  ====>  [('CITY DINER', 1.0), ('CITY VIEW DINER', 0.69), ('PURITY DINER', 0.6), ('CITY WINERY', 0.53)]\n",
            "BILLIARDS  ====>  [('BILLIARDS', 1.0), ('DIY BILLIARDS', 0.6), ('PARK BILLIARDS', 0.56), ('STAR BILLIARDS', 0.56), ('SEVEN BILLIARDS', 0.53)]\n",
            "NOSH EXPRESS  ====>  [('NOSH EXPRESS', 1.0), ('FRESH EXPRESS', 0.59), ('NOSTRAND EXPRESS', 0.58), ('NAYA EXPRESS', 0.53), ('TURKISH EXPRESS', 0.53)]\n",
            "LA PIAZZETTA  ====>  [('LA PIAZZETTA', 1.0), ('LUNETTA PIZZERIA', 0.58)]\n",
            "COSI SANDWICH BAR  ====>  [('COSI SANDWICH BAR', 1.0), ('THE SANDWICH BAR', 0.59)]\n",
            "LONA PIZZA  ====>  [('LONA PIZZA', 1.0), ('BONA PIZZA', 0.69), ('LUNA PIZZA', 0.69), ('CORONA PIZZA', 0.6), ('VERONA PIZZA', 0.6)]\n",
            "D'ANGELOS PIZZA  ====>  [(\"D'ANGELOS PIZZA\", 1.0), (\"D'ANGELO'S PIZZA\", 0.83), (\"D'ANGELO PIZZA\", 0.82), (\"ANGELO'S PIZZA\", 0.63), ('DELIOS PIZZA', 0.53)]\n",
            "FOOD HUT CARIBBEAN CUISINE  ====>  [('FOOD HUT CARIBBEAN CUISINE', 1.0), (\"WRAY'S CARIBBEAN AND SEAFOOD CUISINE\", 0.52)]\n",
            "NOODLE VILLAGE SO GOOD  ====>  [('NOODLE VILLAGE SO GOOD', 1.0), ('NOODLE VILLAGE', 0.58)]\n",
            "FONDA  ====>  [('FONDA', 1.0), ('ONDA', 0.57), (\"L'FONDA\", 0.56)]\n",
            "INSOMNIA  COOKLIES  ====>  [('INSOMNIA  COOKLIES', 1.0), ('INSOMNIA COOKIES', 0.8)]\n",
            "BROTHERS PIZZA  ====>  [('BROTHERS PIZZA', 1.0), ('BROTHER PIZZA', 0.81), ('BROTHERS PIZZA II', 0.74), ('BROTHERS PIZZERIA', 0.74), ('TWO BROTHERS PIZZA', 0.7)]\n",
            "DOMENICK'S PIZZA & RESTAURANT  ====>  [(\"DOMENICK'S PIZZA & RESTAURANT\", 1.0), (\"DIEGO'S PIZZA & RESTAURANT\", 0.63), (\"GIO'S PIZZA & RESTAURANT\", 0.62), (\"DOMINICK'S BAR & RESTAURANT\", 0.61), (\"DANY'S PIZZA RESTAURANT\", 0.59)]\n",
            "GREEN CITY RESTAURANT  ====>  [('GREEN CITY RESTAURANT', 1.0), ('GOLDEN CITY RESTAURANT', 0.73), ('GREEN SKY RESTAURANT', 0.72), ('CITY RESTAURANT', 0.65), ('GREEN JADE RESTAURANT', 0.63)]\n",
            "ASHLEY RESTAURANT  ====>  [('ASHLEY RESTAURANT', 1.0), ('ALMASRY RESTAURANT', 0.61), ('LORELEY RESTAURANT', 0.61), ('ALLEN RESTAURANT', 0.59), ('ASTRO RESTAURANT', 0.59)]\n",
            "NEW HING RESTAURANT  ====>  [('NEW HING RESTAURANT', 1.0), ('NEW LI HING RESTAURANT', 0.87), ('NEW CHOY HING RESTAURANT', 0.8), ('NEW HING LONG RESTAURANT', 0.8), ('NEW HUNG HING RESTAURANT', 0.8)]\n",
            "MEZINI RESTAURANT  ====>  [('MEZINI RESTAURANT', 1.0), ('MARANI RESTAURANT', 0.64), ('MEZCLA RESTAURANT', 0.64), ('MINI STAR RESTAURANT', 0.62), ('BELLINI RESTAURANT', 0.61)]\n",
            "PEQUENO RESTAURANT  ====>  [('PEQUENO RESTAURANT', 1.0), ('PO RESTAURANT', 0.65), ('MI SUENO RESTAURANT', 0.62), ('NO 1 RESTAURANT', 0.59), ('COMA BUENO RESTAURANT', 0.58)]\n",
            "FB9120 HOT DOG CONCESSION  ====>  [('FB9120 HOT DOG CONCESSION', 1.0), ('FB9110 HOT DOG CONCESSION', 0.86), ('FB9090 HOT DOG CONCESSION', 0.79), ('FA8070 HOT DOG CONCESSION', 0.68), ('FB1014 HOT DOG CONCESSION', 0.68)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnLTHvbKKW1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}