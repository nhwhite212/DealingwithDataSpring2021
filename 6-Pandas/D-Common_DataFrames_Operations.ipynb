{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "D-Common_DataFrames_Operations.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hyj5ksaxAtNh",
        "6qBlTup6AtNh",
        "-5C5gHgFAtNi",
        "0KO4mPVgAtNk",
        "M0URu3NdAtNl",
        "YysC_bYpAtNm",
        "NLKWVCtEAtNm",
        "b214nGCQAtNm",
        "b1PDRnKuAtNm"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/master/6-Pandas/D-Common_DataFrames_Operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UlMMwuWAtNL"
      },
      "source": [
        "### Common Pandas Operations\n",
        "\n",
        "We will use the data set from NYC OpenData called \"New York City Leading Causes of Death\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b280aaG3AtNT"
      },
      "source": [
        "# Data set: New York City Leading Causes of Death\n",
        "# https://data.cityofnewyork.us/Health/New-York-City-Leading-Causes-of-Death/jb7j-dtam\n",
        "\n",
        "%matplotlib inline\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsH8vib2AtNV"
      },
      "source": [
        "#### Fetching the data\n",
        "\n",
        "\n",
        "We fetch the data in JSON format using the NYC OpenData API:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diwyNaWxAtNW"
      },
      "source": [
        "url = 'http://data.cityofnewyork.us/api/views/jb7j-dtam/rows.json'\n",
        "results = requests.get(url).json()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grrx69rCAtNW"
      },
      "source": [
        "results.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3fBKiH2AtNX"
      },
      "source": [
        "There are two main fields in the returned JSON. The `meta` part that describes the metadata, and the actual `data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycn-laMWAtNX"
      },
      "source": [
        "results['meta']['view'].keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7b6BAbyAtNY"
      },
      "source": [
        "results['data']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgZCFjabAtNY"
      },
      "source": [
        "### Creating a DataFrame from JSON data\n",
        "\n",
        "Let's create a pandas dataframe from the `results[\"data\"]` part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4_fOt2CAtNZ"
      },
      "source": [
        "df = pd.DataFrame(results[\"data\"])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uf5xjrlqAtNZ"
      },
      "source": [
        "### Adding Column Names\n",
        "\n",
        "Hm, this is kind of ugly without column names...\n",
        "\n",
        "We need to peek at the \"meta\" part to find information about the columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-kZ_3rQAtNa"
      },
      "source": [
        "# This part of the results contains the description and names for the columns\n",
        "columns = results[\"meta\"][\"view\"][\"columns\"]\n",
        "columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXcwuaOAAtNb"
      },
      "source": [
        "# We will create a list of the column names, to reuse it when creating our dataframe\n",
        "headers = [c[\"fieldName\"] for c in columns]\n",
        "headers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgysZ56iAtNb"
      },
      "source": [
        "# Now we also pass a list of column names\n",
        "df = pd.DataFrame(results[\"data\"], columns=headers)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlAQ2p9cAtNc"
      },
      "source": [
        "### Deleting Columns and/or Rows\n",
        "\n",
        "We do not need all these columns. Let's drop a few that we will definitely not use. For that, we will use the `drop` command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKtnH53YAtNc"
      },
      "source": [
        "df.drop(labels = [':sid', ':position', ':meta', ':created_meta', ':updated_meta'], \n",
        "        axis=1, inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pncGZbOAtNc"
      },
      "source": [
        "##### Common Patterns: axis and inplace\n",
        "\n",
        "* The `axis=1` says that we are looking to drop columns. If we had \"axis=0\" we would be dropping rows with the passed id's. The ids for the row is the index value for the row.\n",
        "\n",
        "* The `inplace=True` specifies that we will not be creating a new dataframe, but we just replace the current one, with the new dataframe that has fewer columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "882KFatmAtNd"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHBe25JwAtNd"
      },
      "source": [
        "### Renaming Columns\n",
        "\n",
        "We do not like some of these column names. Let's rename them.\n",
        "\n",
        "We will use a dictionary, for specifying the existing and the new names for the columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw6p12V4AtNd"
      },
      "source": [
        "# This dictionary specifies as a key the existing name of the column, and as value the new name\n",
        "renaming_dict = {\n",
        "    ':id': 'key', \n",
        "    ':created_at': 'created_at', \n",
        "    ':updated_at': 'updated_at'\n",
        "}\n",
        "\n",
        "df.rename(columns=renaming_dict, inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48DgUpfCAtNe"
      },
      "source": [
        "### Creating a row index\n",
        "\n",
        "We can specify that the \"key\" column is the primary key for the table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3735bwS5AtNe"
      },
      "source": [
        "df.set_index(keys=\"key\", inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkAD67i-AtNe"
      },
      "source": [
        "# Delete the line with key value 28DCFFED-C3FA-4C16-BB8D-6AB1B07177A7\n",
        "#df.drop(labels = ['28DCFFED-C3FA-4C16-BB8D-6AB1B07177A7'], axis=0, inplace=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaZ4kItqAtNf"
      },
      "source": [
        "### Converting Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unPVtp37AtNf"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "racaBUpaAtNf"
      },
      "source": [
        "# Let's convert to the right data types the year,count,percent\n",
        "df[\"year\"] = pd.to_numeric(df[\"year\"])\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSwlA4cdAtNg"
      },
      "source": [
        "Sometimes, during the conversion of data, the cells contain values that cannot be properly converted. We can specify how we want pandas to handle such cases. By default, it will raise an exception, and will not allow us to convert the data to a new data type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p0yz4KFAtNg"
      },
      "source": [
        "# This one will cause an error, as the \"deaths\" column contains non-numeric values.\n",
        "df[\"deaths\"] = pd.to_numeric(df[\"deaths\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAANPUfLAtNg"
      },
      "source": [
        "### Handling ERRORS\n",
        "We can pass the `errors` command to specify what should happen. From the [documentation of to_numeric](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_numeric.html), we get:\n",
        "* If ‘raise’, then invalid parsing will raise an exception\n",
        "* If ‘coerce’, then invalid parsing will be set as NaN\n",
        "* If ‘ignore’, then invalid parsing will return the input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9HW8DqcAtNg"
      },
      "source": [
        "df[\"deaths\"] = pd.to_numeric(df[\"deaths\"], errors='coerce')\n",
        "df[\"death_rate\"] = pd.to_numeric(df[\"death_rate\"], errors='coerce')\n",
        "df[\"age_adjusted_death_rate\"] = pd.to_numeric(df[\"age_adjusted_death_rate\"], errors='coerce')\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30sg0i0BAtNg"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyj5ksaxAtNh"
      },
      "source": [
        "#### We will also mark the other values as Categorical."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flEsrMJLAtNh"
      },
      "source": [
        "df[\"sex\"] = pd.Categorical(df[\"sex\"])\n",
        "df[\"race_ethnicity\"] = pd.Categorical(df[\"race_ethnicity\"])\n",
        "df[\"leading_cause\"] = pd.Categorical(df[\"leading_cause\"])\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qBlTup6AtNh"
      },
      "source": [
        "#### And we will also convert the timestamps to dates. Notice that we specify the unit to be `s` which is seconds since 1970."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUrkzpS9AtNi"
      },
      "source": [
        "df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], unit='s')\n",
        "df[\"updated_at\"] = pd.to_datetime(df[\"updated_at\"], unit='s')\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5C5gHgFAtNi"
      },
      "source": [
        "#### Now lets see what we have"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlhO3_oNAtNi"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP7NWin0AtNi"
      },
      "source": [
        "### Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBVOjnGxAtNi"
      },
      "source": [
        "df[\"race_ethnicity\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7u57pXVAtNi"
      },
      "source": [
        "df[\"sex\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q4kixQCAtNj"
      },
      "source": [
        "df[\"leading_cause\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbPSBvhFAtNj"
      },
      "source": [
        "### Pivot Tables\n",
        "\n",
        "Let's create a pivot table now. We are going to put the \"leading cause\" as the row, with sex and race as columns. For the cell values we will use the number of deaths, and we are going to sum (`np.sum`) the values.\n",
        "\n",
        "_Note: You will also find the `pivot` and `crosstab` functions in Pandas. The `pivot_table` function is typically a more general version of both._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_IvJCJGAtNj"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "pivot = pd.pivot_table(df, \n",
        "                       values='deaths', \n",
        "                       index=['leading_cause'], # rows\n",
        "                       columns=['sex', 'race_ethnicity'], # columns\n",
        "                       aggfunc=np.mean) # aggregation function\n",
        "pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-SgkBq5AtNj"
      },
      "source": [
        "And we can easily transpose the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kSUSxwIAtNk"
      },
      "source": [
        "pivot.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0we_d4MBAtNk"
      },
      "source": [
        "# And we can of course, plot:\n",
        "pivot.transpose()[\"Diseases of Heart (I00-I09, I11, I13, I20-I51)\"].plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KO4mPVgAtNk"
      },
      "source": [
        "#### Exercises\n",
        "\n",
        "* Write a function that will change the values for the \"leading cause\" column, and make them shorter. For example, we want to eliminate the codes within the parentheses; the value \"Alzheimer's Disease (G30)\" should become \"Alzheimer's Disease\". Use the `apply` function and/or the `map` function to create a new column with the shortened values. Then use the `drop` command to delete the old `leading_cause` column. \n",
        "* Change the pivot_table to compute the average `age_adjusted_death_rate` instead of the sum of deaths. (Hint: you can use the `numpy.mean` function to compute averages."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV6M31FrAtNk"
      },
      "source": [
        "# Example input: \n",
        "# 'Accidents Except Drug Posioning (V01-X39, X43, X45-X59, Y85-Y86)\n",
        "# Example output\n",
        "# 'Accidents Except Drug Posioning'\n",
        "import re\n",
        "\n",
        "def shorten(cause):\n",
        "    # Get everything before the parentheses\n",
        "    # Python regexes have a slightly different syntax\n",
        "    # But this regex finds all the text (group 1) inside the parentheses followed by any number of \n",
        "    # of characters which are enclosed by parentheses.\n",
        "    # It then returns the first 30 characters of the first group\n",
        "    # i.e. get rid of everything in ()'s, and return the first 30 characters of what is left\n",
        "    regex_expression = r'(.*)\\(.*\\)' # notice that we escape the parentheses\n",
        "    regex= re.compile(regex_expression)\n",
        "    matches = regex.finditer(cause)\n",
        "    for m in matches:\n",
        "        return m.group(1).strip()[:30]\n",
        "    return cause[:30]\n",
        "\n",
        "shorten('Accidents Except Drug Posioning (V01-X39, X43, X45-X59, Y85-Y86)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0URu3NdAtNl"
      },
      "source": [
        "#### Now we use a list comprehension  to loop over the rows in the  dataframe to fix them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iM-NkYf_AtNl"
      },
      "source": [
        "# this is what the results will be \n",
        "[shorten(cause) for cause in set(df['leading_cause'].values)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YysC_bYpAtNm"
      },
      "source": [
        "#### Create a new column named 'cause'  that is the shortened version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7B4KNf6AtNm"
      },
      "source": [
        "df[\"cause\"] = df[\"leading_cause\"].apply(shorten)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLKWVCtEAtNm"
      },
      "source": [
        "#### Create a new pivot table with the shortened causes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIbchAqxAtNm"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "pivot = pd.pivot_table(df, \n",
        "                       values='deaths', \n",
        "                       index=['cause'], # rows\n",
        "                       columns=['sex', 'race_ethnicity'], # columns\n",
        "                       aggfunc=np.mean) # aggregation function\n",
        "pivot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b214nGCQAtNm"
      },
      "source": [
        "#### Round the results so they are more legible"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WX78s6R6AtNm"
      },
      "source": [
        "pivot.round(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1PDRnKuAtNm"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "* Get a new dataset from NYC Open Data. (Go for something small.) Fetch it and load it into a dataframe. Put the right column names into the dataframe, eliminate columns and rows that you do not need. Create a basic plot that summarizes some aspect of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oMnsprLAtNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}