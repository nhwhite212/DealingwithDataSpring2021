{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "A-Matplotlib_and_Pandas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/master/6-Pandas/A-Matplotlib_and_Pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SB9XhSOIiiP2"
      },
      "source": [
        "# Plotting and Visualization\n",
        "\n",
        "There are a handful of third-party Python packages that are suitable for creating scientific plots and visualizations (to name a few: matplotlib, Chaco, PyX, Bokeh, and others)\n",
        "\n",
        "Here, we will focus exclusively on **matplotlib**. It is currently the most robust and feature-rich package available.\n",
        "\n",
        "Furthermore, to build on what we have learned and simplify the generation of plots, we will put extra emphasis on plotting available within pandas.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joxSfowgiiP-"
      },
      "source": [
        "### Visual representation of data\n",
        "\n",
        "We require plots, charts and other statistical graphics for the written communication of quantitative ideas.\n",
        "\n",
        "They allow us to more easily convey relationships and reveal deviations from patterns.\n",
        "\n",
        "Gelman and Unwin 2011:\n",
        "\n",
        "> A well-designed graph can display more information than a table of the same size, and more information than numbers embedded in text. Graphical displays allow and encourage direct visual comparisons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZspFUZSRiiP_"
      },
      "source": [
        "## Matplotlib\n",
        "\n",
        "We typically import matplotlib with the following convention:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIXH6TzYiiQB"
      },
      "source": [
        "%matplotlib inline \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVhNinJviiQC"
      },
      "source": [
        "Let's add the usual libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8j9_rpEiiQC"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDj-GvHxiiQE"
      },
      "source": [
        "And we create some random data to plot:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP7RzRC2iiQE"
      },
      "source": [
        "xvalues = np.random.normal(size=1000)\n",
        "yvalues = np.random.normal(size=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFOH4xVsiiQE"
      },
      "source": [
        "plt.plot([1 ,2 ,3 ,4], [3, 5, 6, 7], 'b+')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKhKiIJ3iiQH"
      },
      "source": [
        "The above plot simply shows two sets of random numbers taken from a normal distribution plotted against one another. The `'ro'` argument is a shorthand argument telling matplotlib that I wanted the points represented as red circles (see our earlier short tutorial with our discussion of Python libraries)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgGS7VbsiiQH"
      },
      "source": [
        "#### Multiple plots superimposed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpyrXMfziiQJ"
      },
      "source": [
        "We can also plot many plots on top of each other:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZBBarTXiiQJ"
      },
      "source": [
        "# evenly sampled values between 0 and 5, at 0.2 intervals\n",
        "t = np.arange(0., 5., 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JsHLTJTiiQK"
      },
      "source": [
        "# red dashes, blue squares, green triangles, magenta line\n",
        "import math\n",
        "\n",
        "plt.plot(t, t, 'r--')\n",
        "plt.plot(t, t**2, 'bs')\n",
        "plt.plot(t, t**1.5, 'g^')\n",
        "plt.plot(t, 2*np.sin(5*t), 'm-')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93ep_tIIiiQK"
      },
      "source": [
        "#### Plotting styles"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPknAlPHiiQL"
      },
      "source": [
        "Matplotlib has also a set of predefined styles available:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKjw3qNbiiQL"
      },
      "source": [
        "print plt.style.available"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0_UAUMhiiQM"
      },
      "source": [
        "#plt.style.use(u'fivethirtyeight')\n",
        "#plt.plot(xvalues, yvalues, 'ro')\n",
        "#plt.xlabel(\"Style: fivethirtyeight\")\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv4b6K0kiiQM"
      },
      "source": [
        "# Set some Pandas options\n",
        "#pd.set_option('display.notebook_repr_html', True)\n",
        "#pd.set_option('display.max_columns', 20)\n",
        "#pd.set_option('display.max_rows', 25)\n",
        "\n",
        "#pd.set_option('display.mpl_style', 'default')\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "#plt.rcParams['figure.figsize'] = (15, 5)\n",
        "#plt.rc_context(rc={'font.family': 'monospace',  'font.weight': 'bold',   'font.size': 10})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNbLhVm7iiQM"
      },
      "source": [
        "We can exercise a little more control by breaking the plotting into a workflow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSagw1ALiiQN"
      },
      "source": [
        "fig = plt.figure(figsize=(10,6))\n",
        "\n",
        "# Create the first subfigure\n",
        "sub1 = fig.add_subplot(2,2,1)\n",
        "sub1.set_xlabel('some random numbers')\n",
        "sub1.set_ylabel('more random numbers')\n",
        "sub1.set_title(\"Random scatterplot\")\n",
        "sub1.plot(np.random.randn(1000), np.random.randn(1000), 'r.')\n",
        "\n",
        "# Create the second subfigure\n",
        "sub2 = fig.add_subplot(2,2,2)\n",
        "sub2.hist(np.random.normal(size=500), bins=15)\n",
        "sub2.set_xlabel('sample')\n",
        "sub2.set_ylabel('cumulative sum')\n",
        "sub2.set_title(\"Normal distrubution\")\n",
        "\n",
        "# Create the third subfigure\n",
        "numpoints = 100\n",
        "x = np.linspace(0, 10, num=numpoints)\n",
        "sub3 = fig.add_subplot(2,2,3)\n",
        "sub3.plot(x, np.sin(x) + x + np.random.randn(numpoints), \"r\")\n",
        "sub3.plot(x, np.sin(x) + 0.5 * x + np.random.randn(numpoints), \"g\")\n",
        "sub3.plot(x, np.sin(x) + 2 * x + np.random.randn(numpoints), \"b\")\n",
        "sub3.set_xlabel('x from 0 to 10')\n",
        "sub3.set_ylabel('function value')\n",
        "\n",
        "# Create the fourth subfigure\n",
        "sub4 = fig.add_subplot(2,2,4)\n",
        "x = np.random.randn(10000)\n",
        "y = np.random.randn(10000)\n",
        "sub4.hist2d(x,y,bins=100);\n",
        "sub4.set_xlabel('x axis title')\n",
        "sub4.set_ylabel('y axis title')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"normalvars.png\", dpi=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA5tts-NiiQN"
      },
      "source": [
        "numpoints=10000\n",
        "data1 = np.random.normal(loc=2.0, scale=1.0, size=numpoints)\n",
        "data2 = np.random.normal(loc=-1.0, scale=3.0, size=numpoints)\n",
        "max_data = np.r_[data1, data2].max()\n",
        "# bins = np.linspace(-max_data, max_data, 10 * max_data + 1)\n",
        "plt.hist(data1, bins=int(np.sqrt(numpoints))+1, normed=True, color=\"#6495ED\", alpha=1.0)\n",
        "plt.hist(data2, bins=int(np.sqrt(numpoints))+1, normed=True, color=\"#F08080\", alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUxpL317iiQO"
      },
      "source": [
        "matplotlib is a relatively low-level plotting package, relative to others. It makes very few assumptions about what constitutes good layout (by design), but has a lot of flexiblility to allow the user to completely customize the look of the output.\n",
        "\n",
        "If you want to make your plots look like the plot above, you can configure the default options for matplotlib. A good idea is to \"steal\" the *matplotlibrc* file from [Huy Nguyen](http://www.huyng.com/posts/sane-color-scheme-for-matplotlib/) and store it under `/usr/local/lib/python2.7/site-packages/matplotlib/mpl-data/matplotlibrc`\n",
        "\n",
        "## Plotting in Pandas\n",
        "\n",
        "On the other hand, Pandas includes methods for DataFrame and Series objects that are relatively high-level, and that make reasonable assumptions about how the plot should look."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19vUdc-liiQO"
      },
      "source": [
        "normals = pd.Series(np.random.normal(size=10))\n",
        "normals.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4HVLpz0iiQP"
      },
      "source": [
        "\n",
        "normals.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EbA4OkFiiQP"
      },
      "source": [
        "Notice that by default a line plot is drawn, and a light grid is included. All of this can be changed, however:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klxOsspWiiQP"
      },
      "source": [
        "normals.cumsum().plot(grid=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abobExTkiiQP"
      },
      "source": [
        "Similarly, for a DataFrame:\n",
        "We'll generate a dataframe  with 3 random series from different probability distributions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKzPvsXsiiQQ"
      },
      "source": [
        "variables = pd.DataFrame({'normal': np.random.normal(size=100), \n",
        "                       'gamma': np.random.gamma(1, size=100), \n",
        "                       'poisson': np.random.poisson(size=100)})\n",
        "variables"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djryVhITiiQQ"
      },
      "source": [
        "variables.cumsum(0).plot(figsize=(10,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0roJcBdiiQQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-rlVrRQiiQR"
      },
      "source": [
        "As an illustration of the high-level nature of Pandas plots, we can split multiple series into subplots with a single argument for `plot`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhzFt0CkiiQR"
      },
      "source": [
        "variables.cumsum(0).plot(subplots=True,figsize=(10,6))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWfM-WZviiQR"
      },
      "source": [
        "Or, we may want to have some series displayed on the secondary y-axis, which can allow for greater detail and less empty space:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AV7S06IiiQS"
      },
      "source": [
        "variables.cumsum(0).plot(secondary_y='normal')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D_idXBIiiQS"
      },
      "source": [
        "If we would like a little more control, we can use matplotlib's `subplots` function directly, and manually assign plots to its axes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGEWbcoPiiQS"
      },
      "source": [
        "for i,var in enumerate(['normal','gamma','poisson']):\n",
        "    print \"i=\",i\n",
        "    print \"var=\",var"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TETUxh_NiiQS"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(12, 4))\n",
        "for i,var in enumerate(['normal','gamma','poisson']):\n",
        "    variables[var].cumsum(0).plot(ax=axes[i], title=var)\n",
        "axes[0].set_ylabel('cumulative sum (normal)')\n",
        "axes[1].set_ylabel('cumulative sum (gamma)')\n",
        "axes[2].set_ylabel('cumulative sum (poisson)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGCeH2Zi5UVi"
      },
      "source": [
        "## One example of how to use random numbers is in evaluating the price of options\n",
        "#### One of the fundamental assumptions of modern finance theory is that stock prices are independent \n",
        "#### and the period to period percent changes have a mean of 0 and are normally distributed (central limit theorem, sum of independent random variables)\n",
        "#### This means that the log of the changes are normally distributed (i.e. log-normal distribution)\n",
        "#### So if we want to evaluate a CALL option for a European option, we need to know the following:\n",
        "1. S = Current value of the underlying asset\n",
        "2. K = Strike price of the option\n",
        "3. t = Life to expiration of the option\n",
        "4. r = Riskless interest rate corresponding to the life of the option\n",
        "5. s = Standard Deviation in the ln(value) of the underlying asset\n",
        "###### We could use the Black-Scholes Model to compute the value\n",
        "###### Or we could simulate many different possible price paths and what the value of the option would be for each one.\n",
        "\n",
        "#### Lets look at that graphically..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9_ISkmO_PwP"
      },
      "source": [
        "Generate 1000 lognormal percent change series of length N with mean zero and variance s2\n",
        "\n",
        "Apply these to the original Price S (cumulatively)\n",
        "\n",
        "These are 1000 possible price paths of the asset\n",
        "\n",
        "Evaluate the price of the option at every time period, with a riskless rate of r \n",
        "\n",
        "negative prices are set to zero\n",
        "\n",
        "Take the average (Expected value of all the option prices)\n",
        "\n",
        "That is the value of the option"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek1zqy3WAKMD"
      },
      "source": [
        "# set the option variables\n",
        "nsim=1000   # number of simulations\n",
        "S= 102.   # Current Price\n",
        "t= 5    #days to call\n",
        "r=.06     # Riskless annual interest rate\n",
        "sannual=.05 # annual volatility\n",
        "s=sannual/252. # Daily volatility (252 trading days)\n",
        "\n",
        "\n",
        "K=102.  #Strike price\n",
        "# generate nsim pct price changes of length t, std s\n",
        "changes= pd.DataFrame(np.random.lognormal(0.0,s, size=(t, nsim)))\n",
        "dir(changes)\n",
        "#print(changes)\n",
        "cumchanges=changes.cumprod()\n",
        "#print(cumchanges)\n",
        "\n",
        "# Apply the cumlative changes to the log of the starting price\n",
        "LogPrices= np.log(S)* cumchanges\n",
        "# Determine Price nsim prices series\n",
        "Prices= np.exp(LogPrices)\n",
        "#Prices.plot(legend=False)\n",
        "# What would S be worth if we just invested it in treasuries for t days.\n",
        "riskfree= S*(1.+r/356.)**t\n",
        "\n",
        "print(\"the risk free ending price is\", riskfree)\n",
        "# Find the prices in the ending period - the riskfree price\n",
        "# note: many of these will be negative\n",
        "OptionValues=Prices-riskfree\n",
        "\n",
        "#print(OptionValues)\n",
        "EndValues=OptionValues[t-1:]\n",
        "\n",
        "print(\"Ending Values are:\")\n",
        "print(EndValues)   \n",
        "# Now set all the ending values to zero if they are negative\n",
        "# First convert to a list\n",
        "EndValues=EndValues.values.tolist()[0]\n",
        "#ignore negative prices\n",
        "for i in range(nsim):\n",
        "  EndValues[i] = max(EndValues[i],0.0) \n",
        "print(\"Endvalues positive\")\n",
        "print(EndValues)\n",
        "# Generate 1000 lognormal percent change series of length N with mean zero and variance s2\n",
        "# Apply these to the original Price S (cumulatively)\n",
        "### These are 1000 possible price paths of the asset\n",
        "### Evaluate the price of the option at every time period, with a riskless rate of r\n",
        "#### Take the average (Expected value of all the option prices)\n",
        "#### That is the value of the option)\n",
        "### But will only exercise those options which are positive\n",
        "\n",
        "OptionValue=np.average(EndValues) +S-K\n",
        "if (OptionValue <0):\n",
        "  OptionValue = 0.0\n",
        "print(\"The option value for an asset whose price is \",S, \"after \",t,\" time periods\", \" with a strike price of \",K, \"and Vol of \",sannual,\" is: \",OptionValue)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRY2WZpgjZnF"
      },
      "source": [
        "### How would we modify the code for an American Option that can be exercised early?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxYBnBOviiQT"
      },
      "source": [
        "## Bar plots\n",
        "\n",
        "Bar plots are useful for displaying and comparing measurable quantities, such as counts or volumes. In Pandas, we just use the `plot` method with a `kind='bar'` argument.\n",
        "\n",
        "For this series of examples, let's load up a dataset with the passengers from Titanic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dcl_3p8lpaM"
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHP5zzGNj4Ks"
      },
      "source": [
        "!curl  -q http://people.stern.nyu.edu/nwhite/DealingwithDataSpring2021/titanic.csv -o data/titanic.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD3V9kegiiQT"
      },
      "source": [
        "titanic = pd.read_csv(\"data/titanic.csv\", sep=\",\")\n",
        "titanic.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YPcJY07iiQT"
      },
      "source": [
        "And let's run a couple of SQL-like queries on the DataFrame object that we just loaded:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAeP6OjQiiQU"
      },
      "source": [
        "titanic.groupby('Pclass').Survived.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlX95w5tiiQU"
      },
      "source": [
        "titanic.groupby('Pclass').Survived.sum().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ForR6bbViiQU"
      },
      "source": [
        "titanic.groupby(['Sex','Pclass']).Survived.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFMA_hVziiQV"
      },
      "source": [
        "titanic.groupby(['Sex','Pclass']).Survived.mean().plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j96M61K9iiQV"
      },
      "source": [
        "death_counts = pd.crosstab([titanic.Pclass, titanic.Sex], titanic.Survived.astype(bool))\n",
        "death_counts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTY8MMTqiiQV"
      },
      "source": [
        "death_counts.plot(kind='bar', stacked=True, color=['red','blue'], grid=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7zGXEqbiiQV"
      },
      "source": [
        "Another way of comparing the groups is to look at the survival *rate*, by adjusting for the number of people in each group.\n",
        "That gives us the percent survival rate by group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "valmoBMZyCGH"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lk75TuV1iiQW"
      },
      "source": [
        "death_counts.div(death_counts.sum(1).astype(float), axis=0).plot(kind='barh', stacked=True, color=['red','blue'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uwJjYxAiiQW"
      },
      "source": [
        "## Histograms\n",
        "\n",
        "Frequenfly it is useful to look at the *distribution* of data before you analyze it. Histograms are a sort of bar graph that displays relative frequencies of data values; hence, the y-axis is always some measure of frequency. This can either be raw counts of values or scaled proportions.\n",
        "\n",
        "For example, we might want to see how the fares were distributed aboard the titanic:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHP2PN5tiiQY"
      },
      "source": [
        "titanic[\"Fare\"].hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMJQVTWwiiQY"
      },
      "source": [
        "The `hist` method puts the continuous fare values into **bins**, trying to make a sensible décision about how many bins to use (or equivalently, how wide the bins are). We can override the default value (10):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUETn8ipiiQZ"
      },
      "source": [
        "titanic.Fare.hist(bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_y3jNbuMiiQZ"
      },
      "source": [
        "There are algorithms for determining an [\"optimal\" number of bins](https://en.wikipedia.org/w/index.php?title=Histogram&oldid=548769683#Number_of_bins_and_width), each of which varies somehow with the number of observations in the data series. Here is the implementation for three such heuristics:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWorrRW8iiQZ"
      },
      "source": [
        "sturges = lambda n: int(np.log2(n) + 1)\n",
        "square_root = lambda n: int(np.sqrt(n))\n",
        "from scipy.stats import kurtosis\n",
        "doanes = lambda data: int(1 + np.log(len(data)) + np.log(1 + kurtosis(data) * (len(data) / 6.) ** 0.5))\n",
        "\n",
        "n = len(titanic)\n",
        "sturges(n), square_root(n), doanes(titanic.Fare.dropna())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeV3ok90iiQZ"
      },
      "source": [
        "titanic.Fare.hist(bins=doanes(titanic.Fare.dropna()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STMFGHS7iiQa"
      },
      "source": [
        "titanic.Fare.hist(bins=sturges(len(titanic)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1rwM9W9iiQb"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Create a histogram for the **ages** of the passengers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlT8P3buiiQb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeTPWOEfiiQb"
      },
      "source": [
        "### your code here\n",
        "titanic.Age.hist(bins=sturges(len(titanic)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mUlMnAIiiQb"
      },
      "source": [
        "## Density plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtWEIrSciiQb"
      },
      "source": [
        "A **density plot** is similar to a histogram in that it describes the distribution of the underlying data, but rather than being a pure empirical representation, it is an *estimate* of the underlying \"true\" distribution. As a result, it is smoothed into a continuous line plot. We create them in Pandas using the `plot` method with `kind='kde'`, where `kde` stands for **kernel density estimate**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEqj74qPiiQb"
      },
      "source": [
        "#df = titanic.fare.dropna()\n",
        "titanic[\"Fare\"].plot(kind='kde', xlim=(0,100), ylim=(0,0.05))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIwcB8siiQd"
      },
      "source": [
        "titanic.Fare.dropna().plot(kind='kde', xlim=(0,600))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVup82hLiiQd"
      },
      "source": [
        "Often, histograms and density plots are shown together:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiqQd1UdiiQd"
      },
      "source": [
        "titanic.Fare.hist(bins=doanes(titanic.Fare.dropna()),  normed=True, color='lightseagreen')\n",
        "titanic.Fare.dropna().plot(kind='kde', xlim=(0,600), style='r-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-_mDildiiQq"
      },
      "source": [
        "Here, we had to normalize the histogram (`normed=True`), since the kernel density is normalized by definition (it is a probability distribution)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAwd1fHeiiQr"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Create a density plot for the **ages** of the passengers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMoACHekiiQr"
      },
      "source": [
        "### your code here\n",
        "titanic.Age.hist(bins=doanes(titanic.Fare.dropna()),  normed=True, color='lightseagreen')\n",
        "titanic.Age.dropna().plot(kind='kde', xlim=(0,80), style='r-')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZIsU2zGiiQs"
      },
      "source": [
        "## Boxplots\n",
        "\n",
        "A different way of visualizing the distribution of data is the boxplot, which is a display of common quantiles; these are typically the quartiles and the lower and upper 5 percent values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXG57AdRiiQs"
      },
      "source": [
        "titanic.boxplot(column='Fare', by='Pclass', grid=False, figsize = (8,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxBgc6wViiQs"
      },
      "source": [
        "You can think of the box plot as viewing the distribution from above. The blue crosses are \"outlier\" points that occur outside the extreme quantiles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF5FGJAgiiQt"
      },
      "source": [
        "One way to add additional information to a boxplot is to overlay the actual data; this is generally most suitable with small- or moderate-sized data series."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpdRYNMeiiQt"
      },
      "source": [
        "bp = titanic.boxplot(column='Age', by='Pclass', grid=False, figsize=(8,8))\n",
        "for i in [1,2,3]:\n",
        "    y = titanic.Age[titanic.Pclass==i].dropna()\n",
        "    # The below is an idiom to create a list of len(y) size, all filled with the value i\n",
        "    x = [i] * len(y)\n",
        "    plt.plot(x, y, 'r.', alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gq8LEY-iiQt"
      },
      "source": [
        "Now, you will notice something unfortunate: We have all the points stacked on top of each other. For this reason, we introduce the notion of **jitter** (i.e., small amount of noise) to allow the data points to be visible: We are going to randomly move the X -axis (Pclass) a little on each point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GT5_FmEiiQt"
      },
      "source": [
        "bp = titanic.boxplot(column='Age', by='Pclass', grid=False, figsize=(8,8))\n",
        "for i in [1,2,3]:\n",
        "    y = titanic.Age[titanic.Pclass==i].dropna()\n",
        "    # Add some random \"jitter\" to the x-axis\n",
        "    x = np.random.normal(i, 0.04, size=len(y))\n",
        "    plt.plot(x, y, 'r.', alpha=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiC6RuaUiiQu"
      },
      "source": [
        "### Some tips:\n",
        "When data are dense, a couple of tricks used above help the visualization:\n",
        "\n",
        "1. reducing the alpha level to make the points partially transparent\n",
        "2. adding random \"jitter\" along the x-axis to avoid overstriking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C4R_AsWiiQu"
      },
      "source": [
        "A related but inferior cousin of the box plot is the so-called dynamite plot, which is just a bar chart with half of an error bar, unfortunately popularized through Excel:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe1Rr9a9iiQv"
      },
      "source": [
        "titanic.groupby('Pclass')['Fare'].mean().plot(kind='bar', yerr=titanic.groupby('Pclass')['Fare'].std())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeDGMeI4iiQv"
      },
      "source": [
        "#### Why is this plot a poor choice?\n",
        "\n",
        "- bar charts should be used for measurable quantities (*e.g.* raw data), not estimates. The area of the bar does not represent anything, since these are estimates derived from the data.\n",
        "- the \"data-ink ratio\" (*sensu* Edward Tufte) is very high. There are only 6 values represented here (3 means and 3 standard deviations).\n",
        "- the plot hides the underlying data.\n",
        "\n",
        "A boxplot is **always** a better choice than a dynamite plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHd2IZhsiiQv"
      },
      "source": [
        "data1 = [150, 155, 175, 200, 245, 255, 395, 300, 305, 320, 375, 400, 420, 430, 440]\n",
        "data2 = [225, 380]\n",
        "\n",
        "fake_data = pd.DataFrame([data1, data2]).transpose()\n",
        "p = fake_data.mean().plot(kind='bar', yerr=fake_data.std(), grid=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmMhxCtGiiQv"
      },
      "source": [
        "fake_data = pd.DataFrame([data1, data2]).transpose()\n",
        "p = fake_data.mean().plot(kind='bar', yerr=fake_data.std(), grid=False)\n",
        "x1, x2 = p.xaxis.get_majorticklocs()\n",
        "plt.plot(np.random.normal(x1, 0.01, size=len(data1)), data1, 'ro')\n",
        "plt.plot([x2]*len(data2), data2, 'ro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJQUFs5-iiQw"
      },
      "source": [
        "## Scatterplots\n",
        "\n",
        "To look at how Pandas does scatterplots, let's load the [baseball sample dataset](https://raw.githubusercontent.com/pydata/pandas/master/doc/data/baseball.csv)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_EK4gynExao"
      },
      "source": [
        "!curl http://people.stern.nyu.edu/nwhite/DealingwithDataSpring2021/data/baseball.csv.gz -o data/baseball.csv.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuTCxFm6P58L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEkVAdiZiiQx"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "baseball = pd.read_csv(\"./data/baseball.csv.gz\")\n",
        "baseball.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4eE7aHUKiiQx"
      },
      "source": [
        "Scatterplots are useful for data exploration, where we seek to uncover relationships among variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAFJ2FdFiiQx"
      },
      "source": [
        "fig = baseball.plot(kind='scatter', x='ab', y='h')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBk1F6L3iiQx"
      },
      "source": [
        "Let's put some limits on the x and y axis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufgQK95biiQx"
      },
      "source": [
        "fig = baseball.plot(kind='scatter', x='ab', y='h', xlim=[0,600], ylim=[0,200], figsize=(5,5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAok7NVhiiQx"
      },
      "source": [
        "We can add additional information to scatterplots by assigning variables to either the size of the symbols or their colors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J2DRx29iiQx"
      },
      "source": [
        "fig = baseball.plot(kind='scatter', x='ab', y='h', xlim=[0,600], ylim=[0,200],  figsize=(5,5), s=baseball.hr*10, alpha=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd0WhDyTiiQx"
      },
      "source": [
        "fig = baseball.plot(kind='scatter', x='ab', y='h', xlim=[0,600], ylim=[0,200], \n",
        "                    figsize=(5,5), c=baseball.hr, s=60, cmap='hot')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUB7q-U2iiQx"
      },
      "source": [
        "To view scatterplots of a large numbers of variables simultaneously, we can use the `scatter_matrix` function. It generates a matrix of pair-wise scatterplots, optionally with histograms or kernel density estimates on the diagonal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q3syx9eiiQy"
      },
      "source": [
        "\n",
        "\n",
        "fig = pd.plotting.scatter_matrix(baseball.loc[:,'r':'sb'], figsize=(12,12), diagonal='kde', alpha=0.8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHRirZ7DiiQy"
      },
      "source": [
        "## Hexagonal Bin Plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzSUMk-kiiQz"
      },
      "source": [
        "The hexagonal is useful when we have a very large number of points to display, and even the addition of jitter cannot transform a scatterplot into something readable. \n",
        "\n",
        "You can create hexagonal bin plots with DataFrame.plot() and kind='hexbin'. Hexbin plots can be a useful alternative to scatter plots if your data are too dense to plot each point individually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4qnFXKDiiQz"
      },
      "source": [
        "df = pd.DataFrame( np.random.randn(10000, 2), columns=['a', 'b'])\n",
        "df['b'] = df['b'] + np.arange(10000)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3joq0nViiQz"
      },
      "source": [
        "df.plot(kind='scatter', x='a', y='b', figsize=(6,4), alpha=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XULlT75wiiQ0"
      },
      "source": [
        "df.plot(kind='hexbin', x='a', y='b', gridsize=40,figsize=(8,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qj_gW-vqiiQ0"
      },
      "source": [
        "A useful keyword argument is gridsize; it controls the number of hexagons in the x-direction, and defaults to 100. A larger gridsize means more, smaller bins."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UT0agw3vbLM3"
      },
      "source": [
        "### LAG PLOT\n",
        "Lag plots are used to check if a data set or time series is random. Random data should not exhibit any structure in the lag plot. Non-random structure implies that the underlying data are not random. The lag argument may be passed, and when lag=1 the plot is essentially data[:-1] vs. data[1:]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJzw-YBZiiQ5"
      },
      "source": [
        "from pandas.plotting import lag_plot\n",
        "plt.figure();\n",
        "# generate a linear line around an oval (np.pi)\n",
        "spacing = np.linspace(-99 * np.pi, 99 * np.pi, num=1000)\n",
        "# generate a series  of random points that have a dependency\n",
        "data = pd.Series(0.1 * np.random.rand(1000) + 0.9 * np.sin(spacing))\n",
        "\n",
        "lag_plot(data);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wNdfWI3bG3o"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCzZk0hGckPZ"
      },
      "source": [
        "### Autocorrelation plot\n",
        "\n",
        "Autocorrelation plots are often used for checking randomness in time series. This is done by computing autocorrelations for data values at varying time lags. If time series is random, such autocorrelations should be near zero for any and all time-lag separations. If time series is non-random then one or more of the autocorrelations will be significantly non-zero. The horizontal lines displayed in the plot correspond to 95% and 99% confidence bands. The dashed line is 99% confidence band. See the Wikipedia entry for more about autocorrelation plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEyc0NOEcpzB"
      },
      "source": [
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "plt.figure();\n",
        "\n",
        "spacing = np.linspace(-9 * np.pi, 9 * np.pi, num=1000)\n",
        "\n",
        "data = pd.Series(0.7 * np.random.rand(1000) + 0.3 * np.sin(spacing))\n",
        "\n",
        "autocorrelation_plot(data);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEZyTZEDMzqv"
      },
      "source": [
        "### These examples should be helpful in your final projects in displaying your data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vup2E6JzM7Zh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}