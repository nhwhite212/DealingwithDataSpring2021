{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "000-SentimentHomework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNkip+dU+UMHlAFEcf1UqX/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/master/000-SentimentHomework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXCaq47v0X5B"
      },
      "source": [
        "# This homework notebook will use the Vader NLTK (Natural Language Toolkit) library to do sentiment analysis on Inaugural Speeches.\n",
        "### All of the speeches are available from download as an NLTK Corpus, as are many other interesting corpuses.\n",
        "#### News stories,Many books, ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpTwKKGP0f82"
      },
      "source": [
        "## First bring in the libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_6zPltU4U-u",
        "outputId": "729084cc-58cb-4929-cb20-09e60d64947e"
      },
      "source": [
        "import nltk\n",
        "# download the  speeches\n",
        "nltk.download('inaugural')\n",
        "# and the puncuation library\n",
        "nltk.download('punkt') \n",
        "# bring in the speaches\n",
        "from nltk.corpus import inaugural"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVKLo-YR8Pc7"
      },
      "source": [
        "### Next we will load in the Vader components, the analyzer and the lexicon to go with it. This will do our sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgNB6BOQ00TL",
        "outputId": "aadc2ac5-39ac-4142-a9a7-d060580da694"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTT8xDI8hVc"
      },
      "source": [
        "### Initialize the analyzer object, so we can use it to analyze text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPDjrxVC0-aj"
      },
      "source": [
        "# Initialize the analyzer, creating our analyzer\n",
        "analyzer=SentimentIntensityAnalyzer()\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFJkSRI48qFb"
      },
      "source": [
        "### Load in the speeches, we will try to get one sentiment analysis per speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWoZbyIx1N-z",
        "outputId": "838e0f72-c2a6-450e-b1bc-c95c052aaa65"
      },
      "source": [
        "# We will just use a few speeches as a test\n",
        "speeches=['1793-Washington.txt','1797-Adams.txt','1805-Jefferson.txt','1841-Harrison.txt','1861-Lincoln.txt','1905-Roosevelt.txt','1937-Roosevelt.txt', '1953-Eisenhower.txt','1961-Kennedy.txt','1981-Reagan.txt',\\\n",
        "          '1993-Clinton.txt','2001-Bush.txt', '2009-Obama.txt','2017-Trump.txt']\n",
        "# print the list of all the fileids\n",
        "print(inaugural.fileids())\n",
        "# Your code here...\n",
        "# use the NLTK fileids method to retrieve ALL of the  inaugurall fileids.\n",
        "print('\\n\\n')\n",
        "print(speeches[0],'---\\n',inaugural.raw(fileids=speeches[0]))"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1789-Washington.txt', '1793-Washington.txt', '1797-Adams.txt', '1801-Jefferson.txt', '1805-Jefferson.txt', '1809-Madison.txt', '1813-Madison.txt', '1817-Monroe.txt', '1821-Monroe.txt', '1825-Adams.txt', '1829-Jackson.txt', '1833-Jackson.txt', '1837-VanBuren.txt', '1841-Harrison.txt', '1845-Polk.txt', '1849-Taylor.txt', '1853-Pierce.txt', '1857-Buchanan.txt', '1861-Lincoln.txt', '1865-Lincoln.txt', '1869-Grant.txt', '1873-Grant.txt', '1877-Hayes.txt', '1881-Garfield.txt', '1885-Cleveland.txt', '1889-Harrison.txt', '1893-Cleveland.txt', '1897-McKinley.txt', '1901-McKinley.txt', '1905-Roosevelt.txt', '1909-Taft.txt', '1913-Wilson.txt', '1917-Wilson.txt', '1921-Harding.txt', '1925-Coolidge.txt', '1929-Hoover.txt', '1933-Roosevelt.txt', '1937-Roosevelt.txt', '1941-Roosevelt.txt', '1945-Roosevelt.txt', '1949-Truman.txt', '1953-Eisenhower.txt', '1957-Eisenhower.txt', '1961-Kennedy.txt', '1965-Johnson.txt', '1969-Nixon.txt', '1973-Nixon.txt', '1977-Carter.txt', '1981-Reagan.txt', '1985-Reagan.txt', '1989-Bush.txt', '1993-Clinton.txt', '1997-Clinton.txt', '2001-Bush.txt', '2005-Bush.txt', '2009-Obama.txt', '2013-Obama.txt', '2017-Trump.txt']\n",
            "\n",
            "\n",
            "\n",
            "1793-Washington.txt ---\n",
            " Fellow citizens, I am again called upon by the voice of my country to execute the functions of its Chief Magistrate. When the occasion proper for it shall arrive, I shall endeavor to express the high sense I entertain of this distinguished honor, and of the confidence which has been reposed in me by the people of united America.\n",
            "\n",
            "Previous to the execution of any official act of the President the Constitution requires an oath of office. This oath I am now about to take, and in your presence: That if it shall be found during my administration of the Government I have in any instance violated willingly or knowingly the injunctions thereof, I may (besides incurring constitutional punishment) be subject to the upbraidings of all who are now witnesses of the present solemn ceremony.\n",
            "\n",
            " \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avdMJYgFBr1R"
      },
      "source": [
        "## So now, we can loop through all of the  speeches, and get their sentiment\n",
        "### Lets build  a  dictionary of the speech name, the length of the speech, and the sentiments from the Vader sentiment analyzer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-_uE8XJCRsa"
      },
      "source": [
        "### first, build a dictionary of the speeches. The key will be the name and the value will be the full text of the speech.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--NtceUFCezZ",
        "outputId": "ee31c4c9-8107-40b0-ae4c-33d48fcfa1df"
      },
      "source": [
        "# create an empty dictionary\n",
        "sdict= {}\n",
        "#loop through the list of speeches (fileids)\n",
        "for speech  in speeches:\n",
        "  # create a dictionary entry for each one where the key is the name and the value is the text\n",
        "  # pull in the raw text for each speech and use the speech fileid as the key\n",
        "  # and the raw text as the value. inaugural.raw takes a list of fileids, we will do one at a time\n",
        "  sdict[speech]= inaugural.raw(fileids=[speech])\n",
        "\n",
        "print(sdict['1797-Adams.txt'][0:200])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "When it was first perceived, in early times, that no middle course for America remained between unlimited submission to a foreign legislature and a total independence of its claims, men of reflection \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAndhpzbD4Su"
      },
      "source": [
        "### Now we are ready to analyze each speech\n",
        "### First: Create our output dictionary\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8AYzZtlEYHA",
        "outputId": "a66fb92a-b8de-4fef-8536-744bcfe50ed3"
      },
      "source": [
        "# Sents will have a key of the speech (i.e. fileid, and the value will be the analyzer score\n",
        "Sents={}\n",
        "# Loop through all of the speeches and analyze it.\n",
        "for speech in speeches:\n",
        "# Invoke our analyzer on the speech\n",
        "  scores= analyzer.polarity_scores(inaugural.raw(fileids=[speech]))\n",
        "  # save the scores ina  dictionary\n",
        "  Sents[speech]= scores\n",
        "# print out the results\n",
        "for Sent in Sents:\n",
        "  print(Sent, '---',Sents[Sent])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1793-Washington.txt --- {'neg': 0.034, 'neu': 0.883, 'pos': 0.083, 'compound': 0.7845}\n",
            "1797-Adams.txt --- {'neg': 0.049, 'neu': 0.692, 'pos': 0.258, 'compound': 1.0}\n",
            "1805-Jefferson.txt --- {'neg': 0.056, 'neu': 0.767, 'pos': 0.177, 'compound': 0.9998}\n",
            "1841-Harrison.txt --- {'neg': 0.072, 'neu': 0.75, 'pos': 0.177, 'compound': 1.0}\n",
            "1861-Lincoln.txt --- {'neg': 0.101, 'neu': 0.767, 'pos': 0.132, 'compound': 0.9991}\n",
            "1905-Roosevelt.txt --- {'neg': 0.074, 'neu': 0.692, 'pos': 0.234, 'compound': 0.9997}\n",
            "1937-Roosevelt.txt --- {'neg': 0.09, 'neu': 0.725, 'pos': 0.185, 'compound': 0.9996}\n",
            "1953-Eisenhower.txt --- {'neg': 0.069, 'neu': 0.67, 'pos': 0.261, 'compound': 1.0}\n",
            "1961-Kennedy.txt --- {'neg': 0.128, 'neu': 0.684, 'pos': 0.187, 'compound': 0.9989}\n",
            "1981-Reagan.txt --- {'neg': 0.079, 'neu': 0.721, 'pos': 0.2, 'compound': 0.9999}\n",
            "1993-Clinton.txt --- {'neg': 0.079, 'neu': 0.737, 'pos': 0.185, 'compound': 0.9997}\n",
            "2001-Bush.txt --- {'neg': 0.105, 'neu': 0.662, 'pos': 0.233, 'compound': 0.9998}\n",
            "2009-Obama.txt --- {'neg': 0.106, 'neu': 0.709, 'pos': 0.185, 'compound': 0.9997}\n",
            "2017-Trump.txt --- {'neg': 0.07, 'neu': 0.708, 'pos': 0.222, 'compound': 0.9998}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BpoowtH9_ud"
      },
      "source": [
        "# It should be easy to distill long sequences of text into a few numbers\n",
        "# Note, we can also use NLTK to pull out entities from the text.\n",
        "### We'll do that next\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIFLYBWM9rIo"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiczubiXXNcc"
      },
      "source": [
        "# download the NLTK perceptron part of speech tagger. It will analyze a sentence and tag each word with its part of speech. There are different taggers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64vFAzUrBBrn",
        "outputId": "1d6cff4e-a1a0-4fc7-bbc1-426cf0b6827f"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUoruv7yXX4R"
      },
      "source": [
        "### create a function that given a text string, tokenizes it into words,\n",
        "\n",
        "### and creates a parts of speech tag for each word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOpFsO8A_Gdn"
      },
      "source": [
        "### create a little function\n",
        "def preprocess(text):\n",
        "  sent=nltk.word_tokenize(text)\n",
        "  sent=nltk.pos_tag(sent)\n",
        "  return sent"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fTSgyD9zQlh"
      },
      "source": [
        "#### Use our function to tokenize and tag each speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2IDr0HYANXd",
        "outputId": "0e9ceef4-3253-4c0b-9c99-d18609485b69"
      },
      "source": [
        "# and call it for every speech\n",
        "# \n",
        "entities = {}\n",
        "\n",
        "for speech in speeches:\n",
        "  # call preprocess to process each raw speech to get the parts of speech\n",
        "  thespeech=preprocess(inaugural.raw(fileids=[speech]))\n",
        "  # thespeech contains a list of tuples containing the word and the part of speech\n",
        "  entities[speech] = thespeech\n",
        "  # Print out the first 10 words and their POS for each speech\n",
        "  print(speech,' ----',thespeech[0:10])\n"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1793-Washington.txt  ---- [('Fellow', 'NNP'), ('citizens', 'NNS'), (',', ','), ('I', 'PRP'), ('am', 'VBP'), ('again', 'RB'), ('called', 'VBN'), ('upon', 'NN'), ('by', 'IN'), ('the', 'DT')]\n",
            "1797-Adams.txt  ---- [('When', 'WRB'), ('it', 'PRP'), ('was', 'VBD'), ('first', 'RB'), ('perceived', 'VBN'), (',', ','), ('in', 'IN'), ('early', 'JJ'), ('times', 'NNS'), (',', ',')]\n",
            "1805-Jefferson.txt  ---- [('Proceeding', 'VBG'), (',', ','), ('fellow', 'JJ'), ('citizens', 'NNS'), (',', ','), ('to', 'TO'), ('that', 'DT'), ('qualification', 'NN'), ('which', 'WDT'), ('the', 'DT')]\n",
            "1841-Harrison.txt  ---- [('Called', 'VBN'), ('from', 'IN'), ('a', 'DT'), ('retirement', 'NN'), ('which', 'WDT'), ('I', 'PRP'), ('had', 'VBD'), ('supposed', 'VBN'), ('was', 'VBD'), ('to', 'TO')]\n",
            "1861-Lincoln.txt  ---- [('Fellow-Citizens', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('United', 'NNP'), ('States', 'NNPS'), (':', ':'), ('In', 'IN'), ('compliance', 'NN'), ('with', 'IN'), ('a', 'DT')]\n",
            "1905-Roosevelt.txt  ---- [('My', 'PRP$'), ('fellow', 'JJ'), ('citizens', 'NNS'), (',', ','), ('no', 'DT'), ('people', 'NNS'), ('on', 'IN'), ('earth', 'NN'), ('have', 'VBP'), ('more', 'JJR')]\n",
            "1937-Roosevelt.txt  ---- [('When', 'WRB'), ('four', 'CD'), ('years', 'NNS'), ('ago', 'IN'), ('we', 'PRP'), ('met', 'VBD'), ('to', 'TO'), ('inaugurate', 'VB'), ('a', 'DT'), ('President', 'NNP')]\n",
            "1953-Eisenhower.txt  ---- [('My', 'PRP$'), ('friends', 'NNS'), (',', ','), ('before', 'IN'), ('I', 'PRP'), ('begin', 'VBP'), ('the', 'DT'), ('expression', 'NN'), ('of', 'IN'), ('those', 'DT')]\n",
            "1961-Kennedy.txt  ---- [('Vice', 'NNP'), ('President', 'NNP'), ('Johnson', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Chief', 'NNP'), ('Justice', 'NNP')]\n",
            "1981-Reagan.txt  ---- [('Senator', 'NNP'), ('Hatfield', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('Chief', 'NNP'), ('Justice', 'NNP'), (',', ','), ('Mr.', 'NNP'), ('President', 'NNP'), (',', ',')]\n",
            "1993-Clinton.txt  ---- [('My', 'PRP$'), ('fellow', 'JJ'), ('citizens', 'NNS'), (',', ','), ('today', 'NN'), ('we', 'PRP'), ('celebrate', 'VBP'), ('the', 'DT'), ('mystery', 'NN'), ('of', 'IN')]\n",
            "2001-Bush.txt  ---- [('President', 'NNP'), ('Clinton', 'NNP'), (',', ','), ('distinguished', 'VBD'), ('guests', 'NNS'), ('and', 'CC'), ('my', 'PRP$'), ('fellow', 'JJ'), ('citizens', 'NNS'), (',', ',')]\n",
            "2009-Obama.txt  ---- [('My', 'PRP$'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('I', 'PRP'), ('stand', 'VBP'), ('here', 'RB'), ('today', 'NN'), ('humbled', 'VBN'), ('by', 'IN')]\n",
            "2017-Trump.txt  ---- [('Chief', 'JJ'), ('Justice', 'NNP'), ('Roberts', 'NNP'), (',', ','), ('President', 'NNP'), ('Carter', 'NNP'), (',', ','), ('President', 'NNP'), ('Clinton', 'NNP'), (',', ',')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9eXRtEGCOvx"
      },
      "source": [
        "# Note that all the entities are:\n",
        "### Proper Nouns('NNP') or Nouns ('NN') or Proper Nouns Plural('NNPS') or Nouns Plural ('NNS')\n",
        "You just need to pull them out of the dictionary ... For now we will just pull singular Nouns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSTK7Ly3AR-2",
        "outputId": "844f0453-14cb-4c54-8e31-085d04c92248"
      },
      "source": [
        "# Initialize our dictionary, the key will be the address, and the value will be the list of nouns in that address\n",
        "Nouns ={}\n",
        "for speech in entities:\n",
        "# each entity in entities is the key (the speech) and the value is a list of tuples [0] = the word, and [1] is the part of speech\n",
        "# Pull out all of the Nouns from each speech\n",
        "  # initialize the list of nouns for this speech\n",
        "  theNouns=[]\n",
        "#Loop through the speeches and the parts of speech of each word\n",
        "  for thespeech in entities[speech]:\n",
        "    #print(theentity[1])\n",
        "    # see if this word is a Noun \n",
        "   # print(thespeech[1])\n",
        "    if (thespeech[1] == 'NN' ):\n",
        "#      print(theentity[0])\n",
        "# if it is, append it to the list of theNouns for this entity\n",
        "      theNouns.append(thespeech[0])\n",
        "    # Set the dictionary element for this entity to the list of the Nouns\n",
        "    Nouns[speech]= theNouns\n",
        "  # start the list for the next speech\n",
        "  theNouns=[]\n",
        "  \n",
        " # print(theNouns)\n",
        "for speech in entities: \n",
        "  # print the first 10 nouns\n",
        "   print(speech, ' ---', Nouns[speech][0:10])\n",
        "\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1793-Washington.txt  --- ['upon', 'voice', 'country', 'occasion', 'proper', 'sense', 'honor', 'confidence', 'execution', 'act']\n",
            "1797-Adams.txt  --- ['course', 'submission', 'legislature', 'independence', 'reflection', 'danger', 'power', 'government', 'country', 'purity']\n",
            "1805-Jefferson.txt  --- ['qualification', 'entrance', 'charge', 'duty', 'sense', 'proof', 'confidence', 'zeal', 'station', 'occasion']\n",
            "1841-Harrison.txt  --- ['retirement', 'residue', 'life', 'executive', 'office', 'nation', 'prescribes', 'qualification', 'performance', 'obedience']\n",
            "1861-Lincoln.txt  --- ['compliance', 'custom', 'presence', 'oath', 'execution', 'office', 'present', 'administration', 'anxiety', 'excitement']\n",
            "1905-Roosevelt.txt  --- ['earth', 'cause', 'spirit', 'boastfulness', 'strength', 'gratitude', 'measure', 'well-being', 'happiness', 'life']\n",
            "1937-Roosevelt.txt  --- ['anxiety', 'spirit', 'fulfillment', 'vision', 'time', 'security', 'peace', 'pursuit', 'happiness', 'temple']\n",
            "1953-Eisenhower.txt  --- ['expression', 'moment', 'privilege', 'prayer', 'moment', 'future', 'executive', 'branch', 'government', 'join']\n",
            "1961-Kennedy.txt  --- ['clergy', 'today', 'victory', 'party', 'celebration', 'freedom', 'end', 'beginning', 'renewal', 'change']\n",
            "1981-Reagan.txt  --- ['today', 'solemn', 'occasion', 'history', 'Nation', 'commonplace', 'occurrence', 'transfer', 'authority', 'place']\n",
            "1993-Clinton.txt  --- ['today', 'mystery', 'renewal', 'ceremony', 'depth', 'winter', 'world', 'spring', 'spring', 'reborn']\n",
            "2001-Bush.txt  --- ['transfer', 'authority', 'history', 'country', 'oath', 'service', 'nation', 'contest', 'spirit', 'grace']\n",
            "2009-Obama.txt  --- ['today', 'task', 'grateful', 'trust', 'mindful', 'service', 'nation', 'generosity', 'cooperation', 'transition']\n",
            "2017-Trump.txt  --- ['world', 'Thank', 'effort', 'country', 'promise', 'course', 'world', 'job', 'transfer', 'power']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Rd58St5pjp2"
      },
      "source": [
        "\n",
        "# Your job\n",
        "\n",
        "1) Run this code for all speeches (You need the fileids for all speeches) (Just replace the speeches list with a list of all the fileids) (One line change)\n",
        "\n",
        "2) Include the other Noun forms  in the list of Nouns (Change one if statement)\n",
        "   \n",
        "\n",
        "3) How many parts of speech are used in each address? \n",
        "(hint, start with the code for Nouns, put just pull all the POS types into a list , then put then in a set.)  There is  sample code that works below:\n",
        "\n",
        "4) What parts of speech does each speech NOT have that is in any of the other speeches? You need to add 1 line to the last cell in the notebook. (This could be a rough measure of vocabulary)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARxq2o4tqq6g",
        "outputId": "bc2acaa0-3970-44a9-dbd7-8245eff7d90f"
      },
      "source": [
        "# Initialize our dictionary, the key will be the address, and the value will be the list of parts of speech  in that address\n",
        "POS ={}\n",
        "ignorel=[':',',','.',\"''\", '``','(',')']\n",
        "ignore=set(ignorel)\n",
        "for speech in entities:\n",
        "# each entity in entities is the key (the speech) and the value is a list of tuples [0] = the word, and [1] is the part of speech\n",
        "# Pull out all of the Nouns from each speech\n",
        "  # initialize the set of parts of speech for this speech\n",
        "  thePOS=set()\n",
        "#Loop through the speeches and the parts of speech of each word\n",
        "  for thespeech in entities[speech]:\n",
        "    if(thespeech[1] not in ignore):\n",
        "       thePOS.add(thespeech[1])\n",
        "  # start the list for the next speech\n",
        "  POS[speech]=thePOS\n",
        "  thePOS=set()\n",
        "\n",
        " # print(theNouns)\n",
        "for speech in entities: \n",
        "   print(speech, 't',' ---', POS[speech])\n",
        "\n"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1793-Washington.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'NN', 'VBN', 'TO', 'WRB', 'VBZ', 'WP', 'WDT', 'CC', 'VBG', 'MD', 'IN', 'NNS'}\n",
            "1797-Adams.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "1805-Jefferson.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "1841-Harrison.txt t  --- {'FW', 'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'NNS', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'WP'}\n",
            "1861-Lincoln.txt t  --- {'FW', 'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'WP$', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'CD', 'NNPS', 'VBD', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "1905-Roosevelt.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'NNS', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'CD', 'VBD', 'WRB', 'VBZ', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'WP'}\n",
            "1937-Roosevelt.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'NNS', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WDT', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'WP'}\n",
            "1953-Eisenhower.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'NN', 'JJR', 'TO', 'VBN', 'CD', 'NNPS', 'VBD', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'IN', 'RP', 'NNS'}\n",
            "1961-Kennedy.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'NNPS', 'VBD', 'WRB', 'VBZ', 'WP', 'WDT', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "1981-Reagan.txt t  --- {'JJ', 'UH', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "1993-Clinton.txt t  --- {'JJ', 'UH', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "2001-Bush.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'TO', 'VBN', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "2009-Obama.txt t  --- {'JJ', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'NNPS', 'VBD', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n",
            "2017-Trump.txt t  --- {'JJ', 'UH', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'NNPS', 'VBD', 'WRB', 'VBZ', 'WP', 'WDT', 'CC', 'VBG', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhuQ7yqn22MX"
      },
      "source": [
        "# Find the common parts of speech across all the speeches\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hVu1aBg3ePE"
      },
      "source": [
        "cwords=set()\n",
        "for speech in entities:\n",
        "  cwords = cwords | set(POS[speech])"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp7ZEFvNrico",
        "outputId": "53fc46c9-9330-42ab-a177-66389bcb2535"
      },
      "source": [
        "print(cwords)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'FW', 'JJ', 'UH', 'RB', 'VB', 'PRP$', 'NNP', 'DT', 'VBP', 'PRP', 'JJS', 'POS', 'WP$', 'NN', 'RBR', 'JJR', 'VBN', 'TO', 'CD', 'VBD', 'NNPS', 'WRB', 'VBZ', 'WP', 'WDT', 'RBS', 'CC', 'VBG', 'PDT', 'MD', 'EX', 'IN', 'RP', 'NNS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5vOoCNd8gHD"
      },
      "source": [
        "### What speeches don't use parts of speech that are used in any speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUR_Hd5c3dLI",
        "outputId": "f4ebbcf3-d1d0-4443-8348-be459faa7dcb"
      },
      "source": [
        "# Now find the words that ARE NOT in the common set.\n",
        "uwords={}\n",
        "for speech in entities:\n",
        "  # Your code HERE\n",
        "  print(speech, '   ',uwords[speech])"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1793-Washington.txt     {'NNPS', 'FW', 'RBR', 'RBS', 'JJR', 'PDT', 'CD', 'EX', 'UH', 'JJS', 'VBD', 'RP', 'POS', 'WP$'}\n",
            "1797-Adams.txt     {'FW', 'UH', 'WP$'}\n",
            "1805-Jefferson.txt     {'FW', 'UH', 'CD', 'JJS'}\n",
            "1841-Harrison.txt     {'UH'}\n",
            "1861-Lincoln.txt     {'POS', 'UH'}\n",
            "1905-Roosevelt.txt     {'FW', 'UH', 'WP$', 'NNPS'}\n",
            "1937-Roosevelt.txt     {'FW', 'UH', 'RBS'}\n",
            "1953-Eisenhower.txt     {'RBR', 'FW', 'EX', 'UH', 'WP$'}\n",
            "1961-Kennedy.txt     {'FW', 'UH', 'RBS'}\n",
            "1981-Reagan.txt     {'FW'}\n",
            "1993-Clinton.txt     {'FW'}\n",
            "2001-Bush.txt     {'FW', 'UH'}\n",
            "2009-Obama.txt     {'FW', 'UH'}\n",
            "2017-Trump.txt     {'FW', 'PDT', 'WP$', 'RBS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc2wS0-d5Jvq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}